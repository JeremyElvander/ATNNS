{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06f17437",
   "metadata": {},
   "source": [
    "Example notebook for defining networks and training expert models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8342ec99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "from keras import initializers\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from keras.metrics import Precision, Recall\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.optimizers.schedules import ExponentialDecay\n",
    "from keras.utils import to_categorical\n",
    "import scipy\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import itertools\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "#Ensuring script directory is correct\n",
    "script_dir = os.path.dirname(os.path.abspath(sys.argv[0]))\n",
    "os.chdir(script_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fe2a89",
   "metadata": {},
   "source": [
    "Necessary Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c45fc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "def build_model(input_dim, layer_neurons, activation='tanh'):\n",
    "    #Setting up generic model inputs based on layers and neurons\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Dense(layer_neurons[0], activation=activation, input_dim=input_dim))\n",
    "    for i in range(1, len(layer_neurons) - 1):\n",
    "        model.add(layers.Dense(layer_neurons[i], activation=activation))\n",
    "    model.add(layers.Dense(layer_neurons[-1], activation='softplus'))\n",
    "    return model\n",
    "\n",
    "def relative_mse(y_true, y_pred):\n",
    "    #Defining MSE loss function\n",
    "    return tf.reduce_mean(tf.square((y_pred - y_true) / (y_true + 1e-6)))\n",
    "\n",
    "def evaluate_metrics(y_test, y_pred, X_test=None, water=False):\n",
    "    #Building evaluation metrics\n",
    "    mape = (1/len(y_test))*np.sum(abs(np.array(y_test)-np.array(y_pred))/(np.array(y_test)))\n",
    "    nmae = (1/np.mean(y_test))*(1/len(y_test))*np.sum(abs(np.array(y_test)-np.array(y_pred)))\n",
    "    rmse = np.sqrt((1/len(y_test))*np.sum((np.array(y_test)-np.array(y_pred))**2))\n",
    "    if water:\n",
    "        #Comment in/out version for ammonium cases\n",
    "        print('NH4 != 0')\n",
    "        unscale_factor = (X_test['NH4+'] + X_test['NH4+']*(X_test['NA+']+X_test['SO42-'] + X_test['NO3-'] + X_test['CL-'])) * (X_test['RH'] / (1 - X_test['RH']))\n",
    "   \n",
    "        y_test_unscaled = np.array(y_test).flatten() * np.array(unscale_factor).flatten()\n",
    "        y_pred_unscaled = np.array(y_pred).flatten() * np.array(unscale_factor).flatten()\n",
    "        mass_error =  (1/(len(y_test_unscaled))) * np.sum((abs((y_test_unscaled*18)-(np.asarray(y_pred_unscaled).reshape(-1)*18)))/((X_test['NH4+']*18)+ X_test['NH4+']*((X_test['NA+']*23) + (X_test['SO42-']*96) + (X_test['NO3-']*62) + (X_test['CL-']*35.5)) + (y_test_unscaled * 18)))\n",
    "\n",
    "        # print('NH4 = 0')\n",
    "        # unscale_factor = (X_test['NA+'] + X_test['NA+']*(X_test['SO42-'] + X_test['NO3-'] + X_test['CL-'])) * (X_test['RH'] / (1 - X_test['RH']))\n",
    "   \n",
    "        # y_test_unscaled = np.array(y_test).flatten() * np.array(unscale_factor).flatten()\n",
    "        # y_pred_unscaled = np.array(y_pred).flatten() * np.array(unscale_factor).flatten()\n",
    "        # mass_error =  (1/(len(y_test_unscaled))) * np.sum((abs((y_test_unscaled*18)-(np.asarray(y_pred_unscaled).reshape(-1)*18)))/((X_test['NA+']*23) + X_test['NA+']*((X_test['SO42-']*96) + (X_test['NO3-']*62) + (X_test['CL-']*35.5)) + (y_test_unscaled * 18)))\n",
    "        return {'RMSE': rmse, 'NMAE': nmae, 'MAPE': mape, 'mass_error': mass_error}\n",
    "    else:\n",
    "        return {'RMSE': rmse, 'NMAE': nmae, 'MAPE': mape}\n",
    "\n",
    "def gaussian_loglik(y_true, y_pred):\n",
    "    #Gaussian loglikelihood\n",
    "    y_true = np.asarray(y_true).ravel()\n",
    "    y_pred = np.asarray(y_pred).ravel()\n",
    "    n = len(y_true)\n",
    "    resid = y_true - y_pred\n",
    "    sigma2 = np.mean(resid**2)\n",
    "    return -0.5 * n * (np.log(2 * np.pi * sigma2) + 1)\n",
    "\n",
    "def logmeanexp(x):\n",
    "    xmax = np.max(x)\n",
    "    return xmax + np.log(np.mean(np.exp(x - xmax)))\n",
    "\n",
    "\n",
    "def train_model(arch, seed, X_trainval, y_trainval, X_test, y_test, batch_size, epochs, patience, \n",
    "                lr_exp_scheduler, filepath, lr_callback = None, water=False):\n",
    "    tf.keras.backend.clear_session()\n",
    "    print(f'Training architecture: {arch}')\n",
    "    set_seeds(seed)\n",
    "    print(f'\\tSeed: {seed}')\n",
    "    #Ammonium present water case\n",
    "    predictors = ['TEMP', 'RH', 'NA+', 'SO42-', 'NO3-', 'CL-']\n",
    "    #Ammonium absent case\n",
    "    #predictors = ['TEMP', 'RH', 'SO42-', 'NO3-', 'CL-']\n",
    "\n",
    "    #Creating train/val spit from the x_trainval\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size = 0.25, shuffle=True, random_state = seed)\n",
    "\n",
    "    #Scaling training, testing data\n",
    "    X_val_copy = X_val.copy()\n",
    "    scalers = {}\n",
    "    for col in ['TEMP', 'RH']:\n",
    "        mean = X_train[col].mean()\n",
    "        std = X_train[col].std(ddof=0)\n",
    "        X_train[col] = (X_train[col] - mean) / std\n",
    "        X_val[col] = (X_val[col] - mean) / std\n",
    "        scalers[col] = (mean, std)\n",
    "    \n",
    "    X_test_copy = X_test.copy()\n",
    "    #Scaling global test data\n",
    "    X_test_scaled = X_test.copy()\n",
    "    for col in ['TEMP', 'RH']:\n",
    "        mean, std = scalers[col]\n",
    "        X_test_scaled[col] = (X_test_scaled[col] - mean) / std\n",
    "    print('\\t\\tConstructing model...')\n",
    "    #model construction\n",
    "\n",
    "    if water:\n",
    "        #Scaling water\n",
    "        # y_train['water_content'] = y_train['water_content']/((X_train['SO42-']+X_train['NO3-']+X_train['CL-']) * ((X_train['RH'])/(1-X_train['RH'])))\n",
    "        # y_val['water_content'] = y_val['water_content']/((X_val['SO42-']+X_val['NO3-']+X_val['CL-']) * ((X_val['RH'])/(1-X_val['RH'])))\n",
    "        # y_test['water_content'] = y_test['water_content']/((X_test_scaled['SO42-']+X_test_scaled['NO3-']+X_test_scaled['CL-']) * ((X_test_scaled['RH'])/(1-X_test_scaled['RH'])))\n",
    "        #model construction\n",
    "        model = build_model(input_dim = len(predictors), layer_neurons=arch)\n",
    "        optimizer = keras.optimizers.legacy.Adam(learning_rate=0.001)\n",
    "        model.compile(optimizer = optimizer, loss = tf.keras.losses.Huber(), metrics=['MeanSquaredError'])\n",
    "    else:\n",
    "        model = build_model(input_dim = len(predictors), layer_neurons=arch)\n",
    "        optimizer = keras.optimizers.legacy.Adam(learning_rate=lr_exp_scheduler)\n",
    "        model.compile(optimizer = optimizer, loss = relative_mse, metrics=['MeanSquaredError'])\n",
    "\n",
    "\n",
    "    #Callbacks\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=patience,\n",
    "        min_delta=0.00005,\n",
    "        mode='min',\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    if lr_callback:\n",
    "        lr_cb = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "    print('\\t\\tTraining...')\n",
    "    #Training\n",
    "    start = time.time()\n",
    "    if water:\n",
    "        history = model.fit(X_train.loc[:,predictors], y_train, validation_data=(X_val.loc[:,predictors], y_val), batch_size=batch_size, epochs=epochs, shuffle=True, callbacks=[early_stopping, lr_cb], verbose=0)\n",
    "    else:\n",
    "        history = model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=batch_size, epochs=epochs, shuffle=True, callbacks=[early_stopping], verbose=0)\n",
    "    end = time.time()\n",
    "    elapsed = end-start\n",
    "    print(f'\\t\\tTraining time: {elapsed} seconds')\n",
    "    #Final validation evaluation\n",
    "    print('\\t\\tEvaluating validation set...')\n",
    "    y_val_pred = model.predict(X_val.loc[:,predictors])\n",
    "    if water:\n",
    "        val_metrics = evaluate_metrics(y_val, y_val_pred, X_val_copy, water = True)\n",
    "    else:\n",
    "        val_metrics = evaluate_metrics(y_val, y_val_pred)\n",
    "    print(f'\\t\\t{val_metrics}')\n",
    "    #Final evaluation on test set\n",
    "    print('\\t\\t Evaluating test set')\n",
    "    y_test_pred = model.predict(X_test_scaled.loc[:,predictors])\n",
    "    if water:\n",
    "        test_metrics = evaluate_metrics(y_test, y_test_pred, X_test_copy, water=True)\n",
    "    else:\n",
    "        test_metrics = evaluate_metrics(y_test, y_test_pred)\n",
    "    print(f'\\t\\t{test_metrics}')\n",
    "    #Extract model complexity\n",
    "    total_params = model.count_params()\n",
    "    #Calculate log likelihood\n",
    "    test_loglike = gaussian_loglik(y_test.values, y_test_pred)\n",
    "\n",
    "    results = {\n",
    "        'n_layers': len(arch),\n",
    "        'neurons': arch,\n",
    "        'seed': seed,\n",
    "        'params': total_params,\n",
    "        'val_RMSE': val_metrics['RMSE'],\n",
    "        'val_MAPE': val_metrics['MAPE'],\n",
    "        'val_NMAE': val_metrics['NMAE'],\n",
    "        'test_RMSE': test_metrics['RMSE'],\n",
    "        'test_MAPE': test_metrics['MAPE'],\n",
    "        'test_NMAE': test_metrics['NMAE'],\n",
    "        'test_loglike': test_loglike,\n",
    "        'train_time':elapsed,\n",
    "        'epochs_trained':len(history.history['loss']),\n",
    "        'training_history': history.history\n",
    "    }\n",
    "    if water:\n",
    "        results['val_mass_error'] = val_metrics['mass_error']\n",
    "        results['test_mass_error'] = test_metrics['mass_error']\n",
    "\n",
    "    model_name = f\"arch_{'_'.join(map(str, arch))}_seed_{seed}\"\n",
    "    save_path = os.path.join(script_dir, filepath, model_name)\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    # 1. Save the full model (Best Practice)\n",
    "    model.save(f\"{save_path}/full_model.keras\")\n",
    "\n",
    "    # 2. Save weights and JSON separately (If you specifically need them)\n",
    "    model.save_weights(f\"{save_path}/weights.weights.h5\")\n",
    "    with open(f\"{save_path}/metadata.json\", \"w\") as f:\n",
    "        f.write(model.to_json())\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc512a5",
   "metadata": {},
   "source": [
    "Loading and transforming data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81a205de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading raw data, editing column names and binning liquid + mixed into one class\n",
    "df = pd.read_parquet(f'/Users/jeremyelvander/Desktop/AQRC Research/ml_files/data_procurement/eaim_training_final.parquet')\n",
    "df = df.drop(columns=['n_H2O_g'])\n",
    "df = df.rename(columns={'n_H2O_aq':'water_content'})\n",
    "df['phase'] = df['phase'].replace(2, 0)\n",
    "df['phase'] = df['phase'].replace(3, 0)\n",
    "\n",
    "#Ensuring correct ratio scaling\n",
    "with open('/Users/jeremyelvander/Desktop/AQRC Research/ml_files/new_models/solid_amm_nit_nonzero.pkl', 'rb') as file:\n",
    "    load_model = pickle.load(file)\n",
    "b = load_model.coef_[0]\n",
    "a = np.exp(load_model.intercept_)\n",
    "\n",
    "df['amm_nit_ratio'] = df['amm_nit']/(a * np.exp(b * (1/df['TEMP'])))\n",
    "\n",
    "#Ensuring correct ratio scaling\n",
    "with open('/Users/jeremyelvander/Desktop/AQRC Research/ml_files/new_models/solid_amm_chl_nonzero_NEW.pkl', 'rb') as file:\n",
    "    load_model = pickle.load(file)\n",
    "b = load_model.coef_[0]\n",
    "a = np.exp(load_model.intercept_)\n",
    "\n",
    "df['amm_chl_ratio'] = df['amm_chl']/(a * np.exp(b * (1/df['TEMP'])))\n",
    "\n",
    "df = df[df['amm_nit_ratio'] <= 1.]\n",
    "df = df[df['amm_chl_ratio'] <= 1.]\n",
    "\n",
    "\n",
    "#Building dataset for NH4 = 0 Case\n",
    "df_nh4_zero = df[df['NH4+'] == 0].copy()\n",
    "cols_zero = ['SO42-', 'NO3-', 'CL-']\n",
    "df_nh4_zero['water_content'] = df_nh4_zero['water_content']/((df_nh4_zero['NA+']+df_nh4_zero['SO42-']+df_nh4_zero['NO3-']+df_nh4_zero['CL-']) * ((df_nh4_zero['RH'])/(1-df_nh4_zero['RH'])))\n",
    "df_nh4_zero.loc[:,cols_zero] = df_nh4_zero[cols_zero].div(df_nh4_zero['NA+'], axis=0)\n",
    "df_na = df_nh4_zero.loc[:,'NA+']\n",
    "#df_nh4_zero.drop(columns=['NH4+', 'NA+'], inplace=True)\n",
    "\n",
    "#Building dataset for NH4 =/= 0 case\n",
    "df_nh4_nonzero = df[df['NH4+'] != 0].copy()\n",
    "cols_nonzero = ['NA+', 'SO42-', 'NO3-', 'CL-']\n",
    "df_nh4_nonzero['water_content'] = df_nh4_nonzero['water_content']/((df_nh4_nonzero['NH4+']+df_nh4_nonzero['NA+']+df_nh4_nonzero['SO42-']+df_nh4_nonzero['NO3-']+df_nh4_nonzero['CL-']) * ((df_nh4_nonzero['RH'])/(1-df_nh4_nonzero['RH'])))\n",
    "df_nh4_nonzero.loc[:,cols_nonzero] = df_nh4_nonzero[cols_nonzero].div(df_nh4_nonzero['NH4+'], axis=0)\n",
    "df_nh4 = df_nh4_nonzero.loc[:,'NH4+']\n",
    "#df_nh4_nonzero.drop(columns=['NH4+'], inplace=True)\n",
    "\n",
    "df_nh4_zero.reset_index(drop=True, inplace=True)\n",
    "df_nh4_nonzero.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8581b8b",
   "metadata": {},
   "source": [
    "NH4+ =/= 0 Phase Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29fab0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TEMP': (297.0698881224604, 17.872031418008184), 'RH': (0.7996590419527222, 0.12668953716056913)}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m     scalers[col] \u001b[38;5;241m=\u001b[39m (mean, std)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(scalers)\n\u001b[0;32m---> 16\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#split for train / test\u001b[39;00m\n\u001b[1;32m     19\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predictors = ['TEMP', 'RH', 'NA+', 'SO42-', 'NO3-', 'CL-']\n",
    "\n",
    "#Setting up training/validation sets\n",
    "X = df_nh4_nonzero.loc[:,predictors]\n",
    "y = df_nh4_nonzero.loc[:,['phase']]\n",
    "\n",
    "#Normalizing temperature and relative humidity\n",
    "scalers = {}\n",
    "for col in ['TEMP', 'RH']:\n",
    "    mean = X[col].mean()\n",
    "    std = X[col].std(ddof=0)\n",
    "    X[col] = (X[col] - mean) / std\n",
    "    scalers[col] = (mean, std)\n",
    "\n",
    "\n",
    "#split for train / test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle=True)\n",
    "\n",
    "#split for val\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25)\n",
    "\n",
    "y_train = y_train.astype(int)\n",
    "y_val = y_val.astype(int)\n",
    "y_test = y_test.astype(int)\n",
    "\n",
    "#Training model\n",
    "phase_classifier = Sequential()\n",
    "phase_classifier.add(Dense(input_dim = 6, units=32, activation='tanh')) # 16\n",
    "phase_classifier.add(Dense(units=16,activation='tanh'))\n",
    "phase_classifier.add(Dense(units=8,activation='tanh')) #6\n",
    "phase_classifier.add(Dense(units=4,activation='tanh')) #new\n",
    "phase_classifier.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "lr_exp_scheduler = ExponentialDecay(\n",
    "    initial_learning_rate = 0.001,\n",
    "    decay_steps=81973,\n",
    "    decay_rate=0.96,\n",
    "    staircase=False\n",
    ")\n",
    "\n",
    "def focal_loss(gamma=2., alpha=.6):\n",
    "    def loss(y_true, y_pred):\n",
    "        y_pred = tf.clip_by_value(y_pred, 1e-7, 1. - 1e-7)\n",
    "        pt = tf.where(tf.equal(y_true, 1), y_pred, 1 - y_pred)\n",
    "        return -tf.reduce_mean(alpha * tf.pow(1. - pt, gamma) * tf.math.log(pt))\n",
    "    return loss\n",
    "\n",
    "optimizer = keras.optimizers.legacy.Adam(learning_rate=lr_exp_scheduler)\n",
    "phase_classifier.compile(optimizer = optimizer, loss = focal_loss(), metrics=['binary_crossentropy', 'accuracy', Precision(), Recall()])\n",
    "\n",
    "#Adding early stopping to prevent overfitting\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=40,\n",
    "    min_delta=0.0005,\n",
    "    mode='max',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train['phase'].values)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "history = phase_classifier.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=512, epochs=1000, shuffle=True, \n",
    "class_weight=class_weight_dict, callbacks=[early_stopping])\n",
    "\n",
    "# phase_classifier.save('/Users/jeremyelvander/Desktop/AQRC Research/ml_files/new_models/phase_classifier_nonzero.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a057ea24",
   "metadata": {},
   "source": [
    "NH4+ =/= 0, Liquid/Mix, Ammonium Nitrate Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f29f302",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5_/y_2p6lf540s0fskbmjbhg1qc0000gn/T/ipykernel_27283/1718721625.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  nonzero_liqmix_pp = df_nh4_nonzero[df_nh4_nonzero['phase']==0][df_nh4_nonzero['amm_nit']!=0].copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 51\u001b[0m\n\u001b[1;32m     49\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(scalers, file)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 51\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m#DELETE ABOVE\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;66;03m#Load and Process Data\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nonzero_liqmix_pp = df_nh4_nonzero[df_nh4_nonzero['phase']==0][df_nh4_nonzero['amm_nit']!=0].copy()\n",
    "\n",
    "# plt.hist(nonzero_liqmix_pp['amm_nit'], bins=100)\n",
    "# plt.xlabel('Ammonium Nitrate (Units)')\n",
    "# plt.ylabel('Count')\n",
    "# plt.title('Ammonium Nitrate (Raw) - NH4 =/= 0, Liquid/Mix Case')\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "#Loading amm_nit solid case exponential model for data normalization\n",
    "with open('/Users/jeremyelvander/Desktop/AQRC Research/ml_files/new_models/solid_amm_nit_nonzero.pkl', 'rb') as file:\n",
    "    load_model = pickle.load(file)\n",
    "b = load_model.coef_[0]\n",
    "a = np.exp(load_model.intercept_)\n",
    "#Transforming data\n",
    "nonzero_liqmix_pp['amm_nit'] = nonzero_liqmix_pp['amm_nit']/(a * np.exp(b * (1/nonzero_liqmix_pp['TEMP'])))\n",
    "\n",
    "# plt.hist(nonzero_liqmix_pp['amm_nit'], bins=100)\n",
    "# plt.xlabel('Ammonium Nitrate (Units)')\n",
    "# plt.ylabel('Count')\n",
    "# plt.title('Ammonium Nitrate (Scaled) - NH4 =/= 0, Liquid/Mix Case')\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "predictors = ['TEMP', 'RH', 'NA+', 'SO42-', 'NO3-', 'CL-']\n",
    "X = nonzero_liqmix_pp.loc[:,predictors].copy()\n",
    "y = nonzero_liqmix_pp.loc[:,['amm_nit']].copy()\n",
    "\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=4722)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #Load and Process Data\n",
    "    filepath = 'NH4_nonzero/amm_nit/'\n",
    "\n",
    "    architectures = [\n",
    "        (4, 1),\n",
    "        (8, 4, 1),\n",
    "        (16, 8, 1),\n",
    "        (20, 10, 5, 1),\n",
    "        (32, 16, 8, 1),\n",
    "        (64, 32, 16, 1),\n",
    "        (128, 64, 32, 16, 1)\n",
    "    ]\n",
    "    seeds = (1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n",
    "    results = []\n",
    "\n",
    "    batch_size = 512\n",
    "    epochs = 500\n",
    "    patience = 40\n",
    "    lr = 0.0005\n",
    "\n",
    "    #Setup scheduler\n",
    "    decay_steps = int((len(X_trainval)*0.75)/batch_size * 25)\n",
    "    lr_exp_scheduler = ExponentialDecay(\n",
    "        initial_learning_rate = lr,\n",
    "        decay_steps=decay_steps,\n",
    "        decay_rate=0.96,\n",
    "        staircase=False\n",
    "    )\n",
    "\n",
    "\n",
    "    #Run with ProcessPoolExecutor\n",
    "    print(\"Starting Training across multiple processes...\")\n",
    "    with ProcessPoolExecutor(max_workers=4) as executor:\n",
    "        futures = [\n",
    "            executor.submit(train_model, arch, seed, X_trainval, y_trainval, X_test, y_test, \n",
    "                            batch_size, epochs, patience, lr_exp_scheduler, filepath, water=False)\n",
    "            for arch, seed in itertools.product(architectures, seeds)\n",
    "        ]\n",
    "        results = [f.result() for f in futures]\n",
    "\n",
    "    #Save Final Results\n",
    "    df_results = pd.DataFrame(results)\n",
    "\n",
    "    df_results.to_csv('/Users/jeremyelvander/Desktop/AQRC Research/ml_files/model_training/NH4_nonzero/amm_nit/nz_lm_amm_nit_nn.csv')\n",
    "    print(\"All models trained and results saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a272f488",
   "metadata": {},
   "source": [
    "NH4+ =/= 0, Liquid/Mix, Ammonium Chloride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b659530",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5_/y_2p6lf540s0fskbmjbhg1qc0000gn/T/ipykernel_27283/367297124.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  nonzero_liqmix_pp = df_nh4_nonzero[df_nh4_nonzero['phase']==0][df_nh4_nonzero['amm_chl']!=0].copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 52\u001b[0m\n\u001b[1;32m     50\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(scalers, file)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 52\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m#DELETE ABOVE\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;66;03m#Load and process data and parameters\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#NH4 =/= 0, Liq/Mix, Amm_Chl Network \n",
    "nonzero_liqmix_pp = df_nh4_nonzero[df_nh4_nonzero['phase']==0][df_nh4_nonzero['amm_chl']!=0].copy()\n",
    "\n",
    "# plt.hist(nonzero_liqmix_pp['amm_chl'], bins=100)\n",
    "# plt.xlabel('Ammonium Chloride (Units)')\n",
    "# plt.ylabel('Count')\n",
    "# plt.title('Ammonium Chloride (Raw) - NH4 =/= 0, Liquid/Mix Case')\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "#Loading amm_nit solid case exponential model for data normalization\n",
    "with open('/Users/jeremyelvander/Desktop/AQRC Research/ml_files/new_models/solid_amm_chl_nonzero_NEW.pkl', 'rb') as file:\n",
    "    load_model = pickle.load(file)\n",
    "b = load_model.coef_[0]\n",
    "a = np.exp(load_model.intercept_)\n",
    "#Transforming data\n",
    "nonzero_liqmix_pp['amm_chl'] = nonzero_liqmix_pp['amm_chl']/(a * np.exp(b * (1/nonzero_liqmix_pp['TEMP'])))\n",
    "\n",
    "# plt.hist(nonzero_liqmix_pp['amm_chl'], bins=100)\n",
    "# plt.xlabel('Ammonium Chloride (Units)')\n",
    "# plt.ylabel('Count')\n",
    "# plt.title('Ammonium Chloride (Raw) - NH4 =/= 0, Liquid/Mix Case')\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "predictors = ['TEMP', 'RH', 'NA+', 'SO42-', 'NO3-', 'CL-']\n",
    "X = nonzero_liqmix_pp.loc[:,predictors].copy()\n",
    "y = nonzero_liqmix_pp.loc[:,['amm_chl']].copy()\n",
    "\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=4722)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #Load and process data and parameters\n",
    "    filepath = 'NH4_nonzero/amm_chl/'\n",
    "    architectures = [\n",
    "    (4, 1),\n",
    "    (8, 4, 1),\n",
    "    (16, 8, 1),\n",
    "    (20, 10, 5, 1),\n",
    "    (32, 16, 8, 1),\n",
    "    (64, 32, 16, 1),\n",
    "    (128, 64, 32, 16, 1)\n",
    "    ]\n",
    "    seeds = (1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n",
    "    results = []\n",
    "\n",
    "    batch_size = 512\n",
    "    epochs = 500\n",
    "    patience = 40\n",
    "    lr = 0.0005\n",
    "    #Setup scheduler\n",
    "    decay_steps = int((len(X_trainval)*0.75)/batch_size * 25)\n",
    "    lr_exp_scheduler = ExponentialDecay(\n",
    "        initial_learning_rate = lr,\n",
    "        decay_steps=decay_steps,\n",
    "        decay_rate=0.96,\n",
    "        staircase=False\n",
    "    )\n",
    "    #Run with ProcessPool\n",
    "    print(\"Starting Training across multiple processes...\")\n",
    "    with ProcessPoolExecutor(max_workers=4) as executor:\n",
    "        futures = [\n",
    "            executor.submit(train_model, arch, seed, X_trainval, y_trainval, X_test, y_test, \n",
    "                            batch_size, epochs, patience, lr_exp_scheduler, filepath, water=False)\n",
    "            for arch, seed in itertools.product(architectures, seeds)\n",
    "        ]\n",
    "        results = [f.result() for f in futures]\n",
    "\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "\n",
    "    df_results.to_csv('/Users/jeremyelvander/Desktop/AQRC Research/ml_files/model_training/NH4_nonzero/amm_chl/nz_lm_amm_chl_nn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fc2ccd",
   "metadata": {},
   "source": [
    "NH4+ =/= 0, Liquid/Mix, Water Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a14082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(scalers, file)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m#DELETE ABOVE\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m#Setting up parameters and loading data\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nonzero_liquid_mix = df_nh4_nonzero[df_nh4_nonzero['phase']==0].copy()\n",
    "nonzero_liquid_mix = nonzero_liquid_mix[nonzero_liquid_mix['water_content'] > 0.009]\n",
    "\n",
    "#Building training/validation sets\n",
    "predictors = ['TEMP', 'RH', 'NA+', 'SO42-', 'NO3-', 'CL-']\n",
    "X = nonzero_liquid_mix#.loc[:,predictors]\n",
    "y = nonzero_liquid_mix.loc[:,['water_content']]\n",
    "\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=4722)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #Setting up parameters and loading data\n",
    "    filepath = 'NH4_nonzero/water_content/'\n",
    "\n",
    "    architectures = [\n",
    "    (4, 1),\n",
    "    (8, 4, 1),\n",
    "    (16, 8, 1),\n",
    "    (20, 10, 5, 1),\n",
    "    (32, 16, 8, 1),\n",
    "    (64, 32, 16, 1),\n",
    "    (128, 64, 32, 16, 1)\n",
    "    ]\n",
    "    seeds = (1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n",
    "    results = []\n",
    "\n",
    "    batch_size = 1024\n",
    "    epochs = 500\n",
    "    patience = 40\n",
    "    #Establishing lr callback\n",
    "    lr_callback = True\n",
    "\n",
    "    lr = 0.0005\n",
    "\n",
    "    decay_steps = int((len(X_trainval)*0.75)/batch_size * 25)\n",
    "    lr_exp_scheduler = ExponentialDecay(\n",
    "        initial_learning_rate = lr,\n",
    "        decay_steps=decay_steps,\n",
    "        decay_rate=0.96,\n",
    "        staircase=False\n",
    "    )\n",
    "\n",
    "    #Running with ProcessPool\n",
    "    with ProcessPoolExecutor(max_workers=4) as executor:\n",
    "        futures=[\n",
    "            executor.submit(train_model, arch, seed, X_trainval, y_trainval, X_test, y_test, batch_size, epochs, patience, \n",
    "                    lr_exp_scheduler, filepath, lr_callback=lr_callback, water=True)\n",
    "            for arch, seed in itertools.product(architectures, seeds)\n",
    "        ]\n",
    "        results = [f.result() for f in futures]\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "\n",
    "    df_results.to_csv('/Users/jeremyelvander/Desktop/AQRC Research/ml_files/model_training/NH4_nonzero/water_content/nz_lm_water_content_nn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1dec74",
   "metadata": {},
   "source": [
    "NH4+ = 0, Phase Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfa63bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1035/1035 [==============================] - 1s 556us/step - loss: 0.1940 - binary_crossentropy: 0.1940 - accuracy: 0.9191 - precision_1: 0.8085 - recall_1: 0.9258 - val_loss: 0.1303 - val_binary_crossentropy: 0.1303 - val_accuracy: 0.9440 - val_precision_1: 0.8701 - val_recall_1: 0.9335\n",
      "Epoch 2/1000\n",
      "1035/1035 [==============================] - 0s 442us/step - loss: 0.1228 - binary_crossentropy: 0.1236 - accuracy: 0.9479 - precision_1: 0.8696 - recall_1: 0.9539 - val_loss: 0.0978 - val_binary_crossentropy: 0.0978 - val_accuracy: 0.9605 - val_precision_1: 0.8953 - val_recall_1: 0.9678\n",
      "Epoch 3/1000\n",
      "1035/1035 [==============================] - 0s 442us/step - loss: 0.0818 - binary_crossentropy: 0.0823 - accuracy: 0.9665 - precision_1: 0.9113 - recall_1: 0.9730 - val_loss: 0.0566 - val_binary_crossentropy: 0.0566 - val_accuracy: 0.9769 - val_precision_1: 0.9377 - val_recall_1: 0.9802\n",
      "Epoch 4/1000\n",
      "1035/1035 [==============================] - 0s 440us/step - loss: 0.0569 - binary_crossentropy: 0.0550 - accuracy: 0.9780 - precision_1: 0.9405 - recall_1: 0.9822 - val_loss: 0.0507 - val_binary_crossentropy: 0.0507 - val_accuracy: 0.9785 - val_precision_1: 0.9414 - val_recall_1: 0.9822\n",
      "Epoch 5/1000\n",
      "1035/1035 [==============================] - 0s 442us/step - loss: 0.0527 - binary_crossentropy: 0.0506 - accuracy: 0.9807 - precision_1: 0.9481 - recall_1: 0.9838 - val_loss: 0.0485 - val_binary_crossentropy: 0.0485 - val_accuracy: 0.9811 - val_precision_1: 0.9463 - val_recall_1: 0.9865\n",
      "Epoch 6/1000\n",
      "1035/1035 [==============================] - 0s 446us/step - loss: 0.0500 - binary_crossentropy: 0.0477 - accuracy: 0.9819 - precision_1: 0.9522 - recall_1: 0.9836 - val_loss: 0.0356 - val_binary_crossentropy: 0.0356 - val_accuracy: 0.9867 - val_precision_1: 0.9795 - val_recall_1: 0.9713\n",
      "Epoch 7/1000\n",
      "1035/1035 [==============================] - 0s 481us/step - loss: 0.0481 - binary_crossentropy: 0.0460 - accuracy: 0.9827 - precision_1: 0.9545 - recall_1: 0.9842 - val_loss: 0.0421 - val_binary_crossentropy: 0.0421 - val_accuracy: 0.9837 - val_precision_1: 0.9538 - val_recall_1: 0.9878\n",
      "Epoch 8/1000\n",
      "1035/1035 [==============================] - 0s 442us/step - loss: 0.0456 - binary_crossentropy: 0.0433 - accuracy: 0.9840 - precision_1: 0.9579 - recall_1: 0.9853 - val_loss: 0.0412 - val_binary_crossentropy: 0.0412 - val_accuracy: 0.9853 - val_precision_1: 0.9564 - val_recall_1: 0.9910\n",
      "Epoch 9/1000\n",
      "1035/1035 [==============================] - 0s 451us/step - loss: 0.0453 - binary_crossentropy: 0.0431 - accuracy: 0.9845 - precision_1: 0.9596 - recall_1: 0.9851 - val_loss: 0.0340 - val_binary_crossentropy: 0.0340 - val_accuracy: 0.9884 - val_precision_1: 0.9705 - val_recall_1: 0.9872\n",
      "Epoch 10/1000\n",
      "1035/1035 [==============================] - 1s 775us/step - loss: 0.0439 - binary_crossentropy: 0.0414 - accuracy: 0.9850 - precision_1: 0.9606 - recall_1: 0.9860 - val_loss: 0.0360 - val_binary_crossentropy: 0.0360 - val_accuracy: 0.9873 - val_precision_1: 0.9646 - val_recall_1: 0.9897\n",
      "Epoch 11/1000\n",
      "1035/1035 [==============================] - 1s 507us/step - loss: 0.0419 - binary_crossentropy: 0.0392 - accuracy: 0.9863 - precision_1: 0.9647 - recall_1: 0.9865 - val_loss: 0.0353 - val_binary_crossentropy: 0.0353 - val_accuracy: 0.9863 - val_precision_1: 0.9666 - val_recall_1: 0.9835\n",
      "Epoch 12/1000\n",
      "1035/1035 [==============================] - 0s 446us/step - loss: 0.0416 - binary_crossentropy: 0.0392 - accuracy: 0.9861 - precision_1: 0.9640 - recall_1: 0.9863 - val_loss: 0.0297 - val_binary_crossentropy: 0.0297 - val_accuracy: 0.9906 - val_precision_1: 0.9806 - val_recall_1: 0.9848\n",
      "Epoch 13/1000\n",
      "1035/1035 [==============================] - 0s 443us/step - loss: 0.0406 - binary_crossentropy: 0.0384 - accuracy: 0.9869 - precision_1: 0.9666 - recall_1: 0.9866 - val_loss: 0.0319 - val_binary_crossentropy: 0.0319 - val_accuracy: 0.9892 - val_precision_1: 0.9731 - val_recall_1: 0.9877\n",
      "Epoch 14/1000\n",
      "1035/1035 [==============================] - 0s 441us/step - loss: 0.0396 - binary_crossentropy: 0.0373 - accuracy: 0.9872 - precision_1: 0.9671 - recall_1: 0.9873 - val_loss: 0.0345 - val_binary_crossentropy: 0.0345 - val_accuracy: 0.9872 - val_precision_1: 0.9658 - val_recall_1: 0.9878\n",
      "Epoch 15/1000\n",
      "1035/1035 [==============================] - 0s 447us/step - loss: 0.0398 - binary_crossentropy: 0.0375 - accuracy: 0.9870 - precision_1: 0.9675 - recall_1: 0.9861 - val_loss: 0.0376 - val_binary_crossentropy: 0.0376 - val_accuracy: 0.9858 - val_precision_1: 0.9584 - val_recall_1: 0.9908\n",
      "Epoch 16/1000\n",
      "1035/1035 [==============================] - 0s 445us/step - loss: 0.0387 - binary_crossentropy: 0.0364 - accuracy: 0.9876 - precision_1: 0.9682 - recall_1: 0.9873 - val_loss: 0.0377 - val_binary_crossentropy: 0.0377 - val_accuracy: 0.9856 - val_precision_1: 0.9573 - val_recall_1: 0.9912\n",
      "Epoch 17/1000\n",
      "1035/1035 [==============================] - 1s 485us/step - loss: 0.0379 - binary_crossentropy: 0.0354 - accuracy: 0.9880 - precision_1: 0.9689 - recall_1: 0.9881 - val_loss: 0.0417 - val_binary_crossentropy: 0.0417 - val_accuracy: 0.9845 - val_precision_1: 0.9528 - val_recall_1: 0.9922\n",
      "Epoch 18/1000\n",
      "1035/1035 [==============================] - 0s 457us/step - loss: 0.0372 - binary_crossentropy: 0.0350 - accuracy: 0.9885 - precision_1: 0.9708 - recall_1: 0.9879 - val_loss: 0.0399 - val_binary_crossentropy: 0.0399 - val_accuracy: 0.9855 - val_precision_1: 0.9547 - val_recall_1: 0.9938\n",
      "Epoch 19/1000\n",
      "1035/1035 [==============================] - 0s 473us/step - loss: 0.0374 - binary_crossentropy: 0.0351 - accuracy: 0.9880 - precision_1: 0.9691 - recall_1: 0.9882 - val_loss: 0.0293 - val_binary_crossentropy: 0.0293 - val_accuracy: 0.9892 - val_precision_1: 0.9821 - val_recall_1: 0.9780\n",
      "Epoch 20/1000\n",
      "1035/1035 [==============================] - 0s 435us/step - loss: 0.0363 - binary_crossentropy: 0.0341 - accuracy: 0.9884 - precision_1: 0.9701 - recall_1: 0.9884 - val_loss: 0.0295 - val_binary_crossentropy: 0.0295 - val_accuracy: 0.9898 - val_precision_1: 0.9728 - val_recall_1: 0.9903\n",
      "Epoch 21/1000\n",
      "1035/1035 [==============================] - 0s 443us/step - loss: 0.0361 - binary_crossentropy: 0.0340 - accuracy: 0.9885 - precision_1: 0.9708 - recall_1: 0.9881 - val_loss: 0.0432 - val_binary_crossentropy: 0.0432 - val_accuracy: 0.9846 - val_precision_1: 0.9522 - val_recall_1: 0.9932\n",
      "Epoch 22/1000\n",
      "1035/1035 [==============================] - 0s 439us/step - loss: 0.0353 - binary_crossentropy: 0.0331 - accuracy: 0.9889 - precision_1: 0.9713 - recall_1: 0.9890 - val_loss: 0.0327 - val_binary_crossentropy: 0.0327 - val_accuracy: 0.9883 - val_precision_1: 0.9652 - val_recall_1: 0.9927\n",
      "Epoch 23/1000\n",
      "1035/1035 [==============================] - 0s 480us/step - loss: 0.0358 - binary_crossentropy: 0.0339 - accuracy: 0.9884 - precision_1: 0.9697 - recall_1: 0.9888 - val_loss: 0.0254 - val_binary_crossentropy: 0.0254 - val_accuracy: 0.9916 - val_precision_1: 0.9837 - val_recall_1: 0.9853\n",
      "Epoch 24/1000\n",
      "1035/1035 [==============================] - 0s 441us/step - loss: 0.0344 - binary_crossentropy: 0.0324 - accuracy: 0.9891 - precision_1: 0.9721 - recall_1: 0.9888 - val_loss: 0.0340 - val_binary_crossentropy: 0.0340 - val_accuracy: 0.9882 - val_precision_1: 0.9637 - val_recall_1: 0.9942\n",
      "Epoch 25/1000\n",
      "1035/1035 [==============================] - 0s 443us/step - loss: 0.0338 - binary_crossentropy: 0.0317 - accuracy: 0.9892 - precision_1: 0.9723 - recall_1: 0.9889 - val_loss: 0.0305 - val_binary_crossentropy: 0.0305 - val_accuracy: 0.9893 - val_precision_1: 0.9680 - val_recall_1: 0.9933\n",
      "Epoch 26/1000\n",
      "1035/1035 [==============================] - 0s 441us/step - loss: 0.0334 - binary_crossentropy: 0.0314 - accuracy: 0.9893 - precision_1: 0.9724 - recall_1: 0.9891 - val_loss: 0.0269 - val_binary_crossentropy: 0.0269 - val_accuracy: 0.9907 - val_precision_1: 0.9773 - val_recall_1: 0.9887\n",
      "Epoch 27/1000\n",
      "1035/1035 [==============================] - 0s 444us/step - loss: 0.0335 - binary_crossentropy: 0.0316 - accuracy: 0.9891 - precision_1: 0.9720 - recall_1: 0.9890 - val_loss: 0.0360 - val_binary_crossentropy: 0.0360 - val_accuracy: 0.9873 - val_precision_1: 0.9617 - val_recall_1: 0.9928\n",
      "Epoch 28/1000\n",
      "1035/1035 [==============================] - 0s 442us/step - loss: 0.0327 - binary_crossentropy: 0.0308 - accuracy: 0.9897 - precision_1: 0.9738 - recall_1: 0.9891 - val_loss: 0.0274 - val_binary_crossentropy: 0.0274 - val_accuracy: 0.9901 - val_precision_1: 0.9801 - val_recall_1: 0.9837\n",
      "Epoch 29/1000\n",
      "1035/1035 [==============================] - 0s 474us/step - loss: 0.0325 - binary_crossentropy: 0.0305 - accuracy: 0.9895 - precision_1: 0.9733 - recall_1: 0.9890 - val_loss: 0.0335 - val_binary_crossentropy: 0.0335 - val_accuracy: 0.9885 - val_precision_1: 0.9632 - val_recall_1: 0.9957\n",
      "Epoch 30/1000\n",
      "1035/1035 [==============================] - 0s 461us/step - loss: 0.0316 - binary_crossentropy: 0.0298 - accuracy: 0.9900 - precision_1: 0.9746 - recall_1: 0.9895 - val_loss: 0.0317 - val_binary_crossentropy: 0.0317 - val_accuracy: 0.9889 - val_precision_1: 0.9681 - val_recall_1: 0.9918\n",
      "Epoch 31/1000\n",
      "1035/1035 [==============================] - 0s 452us/step - loss: 0.0315 - binary_crossentropy: 0.0297 - accuracy: 0.9902 - precision_1: 0.9755 - recall_1: 0.9894 - val_loss: 0.0242 - val_binary_crossentropy: 0.0242 - val_accuracy: 0.9916 - val_precision_1: 0.9855 - val_recall_1: 0.9837\n",
      "Epoch 32/1000\n",
      "1035/1035 [==============================] - 0s 446us/step - loss: 0.0316 - binary_crossentropy: 0.0296 - accuracy: 0.9898 - precision_1: 0.9746 - recall_1: 0.9889 - val_loss: 0.0247 - val_binary_crossentropy: 0.0247 - val_accuracy: 0.9911 - val_precision_1: 0.9801 - val_recall_1: 0.9873\n",
      "Epoch 33/1000\n",
      "1035/1035 [==============================] - 0s 439us/step - loss: 0.0314 - binary_crossentropy: 0.0295 - accuracy: 0.9899 - precision_1: 0.9744 - recall_1: 0.9893 - val_loss: 0.0244 - val_binary_crossentropy: 0.0244 - val_accuracy: 0.9913 - val_precision_1: 0.9798 - val_recall_1: 0.9885\n",
      "Epoch 34/1000\n",
      "1035/1035 [==============================] - 0s 443us/step - loss: 0.0302 - binary_crossentropy: 0.0282 - accuracy: 0.9901 - precision_1: 0.9752 - recall_1: 0.9895 - val_loss: 0.0277 - val_binary_crossentropy: 0.0277 - val_accuracy: 0.9901 - val_precision_1: 0.9722 - val_recall_1: 0.9918\n",
      "Epoch 35/1000\n",
      "1035/1035 [==============================] - 0s 468us/step - loss: 0.0301 - binary_crossentropy: 0.0282 - accuracy: 0.9906 - precision_1: 0.9762 - recall_1: 0.9900 - val_loss: 0.0262 - val_binary_crossentropy: 0.0262 - val_accuracy: 0.9908 - val_precision_1: 0.9735 - val_recall_1: 0.9933\n",
      "Epoch 36/1000\n",
      "1035/1035 [==============================] - 0s 443us/step - loss: 0.0297 - binary_crossentropy: 0.0277 - accuracy: 0.9908 - precision_1: 0.9773 - recall_1: 0.9894 - val_loss: 0.0297 - val_binary_crossentropy: 0.0297 - val_accuracy: 0.9901 - val_precision_1: 0.9713 - val_recall_1: 0.9930\n",
      "Epoch 37/1000\n",
      "1035/1035 [==============================] - 0s 440us/step - loss: 0.0290 - binary_crossentropy: 0.0271 - accuracy: 0.9908 - precision_1: 0.9768 - recall_1: 0.9902 - val_loss: 0.0230 - val_binary_crossentropy: 0.0230 - val_accuracy: 0.9922 - val_precision_1: 0.9828 - val_recall_1: 0.9888\n",
      "Epoch 38/1000\n",
      "1035/1035 [==============================] - 0s 442us/step - loss: 0.0290 - binary_crossentropy: 0.0270 - accuracy: 0.9908 - precision_1: 0.9774 - recall_1: 0.9895 - val_loss: 0.0302 - val_binary_crossentropy: 0.0302 - val_accuracy: 0.9893 - val_precision_1: 0.9680 - val_recall_1: 0.9937\n",
      "Epoch 39/1000\n",
      "1035/1035 [==============================] - 0s 442us/step - loss: 0.0291 - binary_crossentropy: 0.0274 - accuracy: 0.9907 - precision_1: 0.9762 - recall_1: 0.9905 - val_loss: 0.0245 - val_binary_crossentropy: 0.0245 - val_accuracy: 0.9913 - val_precision_1: 0.9821 - val_recall_1: 0.9858\n",
      "Epoch 40/1000\n",
      "1035/1035 [==============================] - 0s 447us/step - loss: 0.0287 - binary_crossentropy: 0.0269 - accuracy: 0.9910 - precision_1: 0.9771 - recall_1: 0.9904 - val_loss: 0.0251 - val_binary_crossentropy: 0.0251 - val_accuracy: 0.9908 - val_precision_1: 0.9867 - val_recall_1: 0.9792\n",
      "Epoch 41/1000\n",
      "1035/1035 [==============================] - 0s 469us/step - loss: 0.0286 - binary_crossentropy: 0.0267 - accuracy: 0.9908 - precision_1: 0.9772 - recall_1: 0.9899 - val_loss: 0.0237 - val_binary_crossentropy: 0.0237 - val_accuracy: 0.9926 - val_precision_1: 0.9801 - val_recall_1: 0.9930\n",
      "Epoch 42/1000\n",
      "1035/1035 [==============================] - 0s 442us/step - loss: 0.0282 - binary_crossentropy: 0.0265 - accuracy: 0.9913 - precision_1: 0.9784 - recall_1: 0.9902 - val_loss: 0.0306 - val_binary_crossentropy: 0.0306 - val_accuracy: 0.9898 - val_precision_1: 0.9690 - val_recall_1: 0.9943\n",
      "Epoch 43/1000\n",
      "1035/1035 [==============================] - 0s 441us/step - loss: 0.0279 - binary_crossentropy: 0.0262 - accuracy: 0.9913 - precision_1: 0.9782 - recall_1: 0.9905 - val_loss: 0.0271 - val_binary_crossentropy: 0.0271 - val_accuracy: 0.9906 - val_precision_1: 0.9714 - val_recall_1: 0.9947\n",
      "Epoch 44/1000\n",
      "1035/1035 [==============================] - 0s 458us/step - loss: 0.0281 - binary_crossentropy: 0.0263 - accuracy: 0.9911 - precision_1: 0.9779 - recall_1: 0.9899 - val_loss: 0.0207 - val_binary_crossentropy: 0.0207 - val_accuracy: 0.9936 - val_precision_1: 0.9891 - val_recall_1: 0.9873\n",
      "Epoch 45/1000\n",
      "1035/1035 [==============================] - 0s 440us/step - loss: 0.0277 - binary_crossentropy: 0.0261 - accuracy: 0.9912 - precision_1: 0.9776 - recall_1: 0.9907 - val_loss: 0.0260 - val_binary_crossentropy: 0.0260 - val_accuracy: 0.9914 - val_precision_1: 0.9808 - val_recall_1: 0.9877\n",
      "Epoch 46/1000\n",
      "1035/1035 [==============================] - 0s 441us/step - loss: 0.0275 - binary_crossentropy: 0.0256 - accuracy: 0.9911 - precision_1: 0.9775 - recall_1: 0.9906 - val_loss: 0.0217 - val_binary_crossentropy: 0.0217 - val_accuracy: 0.9922 - val_precision_1: 0.9849 - val_recall_1: 0.9863\n",
      "Epoch 47/1000\n",
      "1035/1035 [==============================] - 0s 470us/step - loss: 0.0269 - binary_crossentropy: 0.0250 - accuracy: 0.9916 - precision_1: 0.9788 - recall_1: 0.9908 - val_loss: 0.0219 - val_binary_crossentropy: 0.0219 - val_accuracy: 0.9926 - val_precision_1: 0.9844 - val_recall_1: 0.9885\n",
      "Epoch 48/1000\n",
      "1035/1035 [==============================] - 0s 442us/step - loss: 0.0269 - binary_crossentropy: 0.0252 - accuracy: 0.9911 - precision_1: 0.9778 - recall_1: 0.9902 - val_loss: 0.0215 - val_binary_crossentropy: 0.0215 - val_accuracy: 0.9922 - val_precision_1: 0.9841 - val_recall_1: 0.9875\n",
      "Epoch 49/1000\n",
      "1035/1035 [==============================] - 0s 440us/step - loss: 0.0270 - binary_crossentropy: 0.0253 - accuracy: 0.9913 - precision_1: 0.9782 - recall_1: 0.9906 - val_loss: 0.0236 - val_binary_crossentropy: 0.0236 - val_accuracy: 0.9924 - val_precision_1: 0.9773 - val_recall_1: 0.9953\n",
      "Epoch 50/1000\n",
      "1035/1035 [==============================] - 0s 470us/step - loss: 0.0265 - binary_crossentropy: 0.0247 - accuracy: 0.9915 - precision_1: 0.9782 - recall_1: 0.9913 - val_loss: 0.0228 - val_binary_crossentropy: 0.0228 - val_accuracy: 0.9914 - val_precision_1: 0.9925 - val_recall_1: 0.9758\n",
      "Epoch 51/1000\n",
      "1035/1035 [==============================] - 0s 441us/step - loss: 0.0264 - binary_crossentropy: 0.0247 - accuracy: 0.9916 - precision_1: 0.9786 - recall_1: 0.9912 - val_loss: 0.0230 - val_binary_crossentropy: 0.0230 - val_accuracy: 0.9922 - val_precision_1: 0.9780 - val_recall_1: 0.9938\n",
      "Epoch 52/1000\n",
      "1035/1035 [==============================] - 0s 440us/step - loss: 0.0259 - binary_crossentropy: 0.0242 - accuracy: 0.9918 - precision_1: 0.9792 - recall_1: 0.9913 - val_loss: 0.0212 - val_binary_crossentropy: 0.0212 - val_accuracy: 0.9924 - val_precision_1: 0.9793 - val_recall_1: 0.9930\n",
      "Epoch 53/1000\n",
      "1035/1035 [==============================] - 0s 467us/step - loss: 0.0260 - binary_crossentropy: 0.0242 - accuracy: 0.9920 - precision_1: 0.9798 - recall_1: 0.9912 - val_loss: 0.0198 - val_binary_crossentropy: 0.0198 - val_accuracy: 0.9936 - val_precision_1: 0.9874 - val_recall_1: 0.9890\n",
      "Epoch 54/1000\n",
      "1035/1035 [==============================] - 0s 442us/step - loss: 0.0262 - binary_crossentropy: 0.0244 - accuracy: 0.9916 - precision_1: 0.9790 - recall_1: 0.9908 - val_loss: 0.0231 - val_binary_crossentropy: 0.0231 - val_accuracy: 0.9914 - val_precision_1: 0.9747 - val_recall_1: 0.9943\n",
      "Epoch 55/1000\n",
      "1035/1035 [==============================] - 0s 442us/step - loss: 0.0252 - binary_crossentropy: 0.0235 - accuracy: 0.9919 - precision_1: 0.9797 - recall_1: 0.9912 - val_loss: 0.0214 - val_binary_crossentropy: 0.0214 - val_accuracy: 0.9929 - val_precision_1: 0.9801 - val_recall_1: 0.9942\n",
      "Epoch 56/1000\n",
      "1035/1035 [==============================] - 0s 453us/step - loss: 0.0251 - binary_crossentropy: 0.0234 - accuracy: 0.9919 - precision_1: 0.9795 - recall_1: 0.9915 - val_loss: 0.0222 - val_binary_crossentropy: 0.0222 - val_accuracy: 0.9922 - val_precision_1: 0.9804 - val_recall_1: 0.9910\n",
      "Epoch 57/1000\n",
      "1035/1035 [==============================] - 0s 440us/step - loss: 0.0255 - binary_crossentropy: 0.0237 - accuracy: 0.9917 - precision_1: 0.9786 - recall_1: 0.9916 - val_loss: 0.0204 - val_binary_crossentropy: 0.0204 - val_accuracy: 0.9932 - val_precision_1: 0.9841 - val_recall_1: 0.9910\n",
      "Epoch 58/1000\n",
      "1035/1035 [==============================] - 1s 493us/step - loss: 0.0248 - binary_crossentropy: 0.0231 - accuracy: 0.9922 - precision_1: 0.9801 - recall_1: 0.9917 - val_loss: 0.0200 - val_binary_crossentropy: 0.0200 - val_accuracy: 0.9933 - val_precision_1: 0.9819 - val_recall_1: 0.9937\n",
      "Epoch 59/1000\n",
      "1035/1035 [==============================] - 0s 446us/step - loss: 0.0246 - binary_crossentropy: 0.0229 - accuracy: 0.9921 - precision_1: 0.9801 - recall_1: 0.9917 - val_loss: 0.0277 - val_binary_crossentropy: 0.0277 - val_accuracy: 0.9897 - val_precision_1: 0.9667 - val_recall_1: 0.9965\n",
      "Epoch 60/1000\n",
      "1035/1035 [==============================] - 0s 447us/step - loss: 0.0247 - binary_crossentropy: 0.0229 - accuracy: 0.9922 - precision_1: 0.9805 - recall_1: 0.9912 - val_loss: 0.0180 - val_binary_crossentropy: 0.0180 - val_accuracy: 0.9940 - val_precision_1: 0.9885 - val_recall_1: 0.9893\n",
      "Epoch 61/1000\n",
      "1035/1035 [==============================] - 0s 447us/step - loss: 0.0242 - binary_crossentropy: 0.0222 - accuracy: 0.9927 - precision_1: 0.9817 - recall_1: 0.9918 - val_loss: 0.0190 - val_binary_crossentropy: 0.0190 - val_accuracy: 0.9939 - val_precision_1: 0.9851 - val_recall_1: 0.9925\n",
      "Epoch 62/1000\n",
      "1035/1035 [==============================] - 1s 570us/step - loss: 0.0245 - binary_crossentropy: 0.0228 - accuracy: 0.9920 - precision_1: 0.9799 - recall_1: 0.9914 - val_loss: 0.0194 - val_binary_crossentropy: 0.0194 - val_accuracy: 0.9936 - val_precision_1: 0.9835 - val_recall_1: 0.9932\n",
      "Epoch 63/1000\n",
      "1035/1035 [==============================] - 1s 744us/step - loss: 0.0241 - binary_crossentropy: 0.0224 - accuracy: 0.9923 - precision_1: 0.9805 - recall_1: 0.9917 - val_loss: 0.0212 - val_binary_crossentropy: 0.0212 - val_accuracy: 0.9932 - val_precision_1: 0.9808 - val_recall_1: 0.9947\n",
      "Epoch 64/1000\n",
      "1035/1035 [==============================] - 1s 587us/step - loss: 0.0235 - binary_crossentropy: 0.0219 - accuracy: 0.9923 - precision_1: 0.9805 - recall_1: 0.9917 - val_loss: 0.0195 - val_binary_crossentropy: 0.0195 - val_accuracy: 0.9939 - val_precision_1: 0.9842 - val_recall_1: 0.9937\n",
      "Epoch 65/1000\n",
      "1035/1035 [==============================] - 1s 486us/step - loss: 0.0236 - binary_crossentropy: 0.0219 - accuracy: 0.9926 - precision_1: 0.9819 - recall_1: 0.9915 - val_loss: 0.0178 - val_binary_crossentropy: 0.0178 - val_accuracy: 0.9940 - val_precision_1: 0.9897 - val_recall_1: 0.9883\n",
      "Epoch 66/1000\n",
      "1035/1035 [==============================] - 0s 473us/step - loss: 0.0236 - binary_crossentropy: 0.0219 - accuracy: 0.9925 - precision_1: 0.9816 - recall_1: 0.9915 - val_loss: 0.0199 - val_binary_crossentropy: 0.0199 - val_accuracy: 0.9931 - val_precision_1: 0.9804 - val_recall_1: 0.9945\n",
      "Epoch 67/1000\n",
      "1035/1035 [==============================] - 0s 475us/step - loss: 0.0239 - binary_crossentropy: 0.0222 - accuracy: 0.9922 - precision_1: 0.9804 - recall_1: 0.9917 - val_loss: 0.0164 - val_binary_crossentropy: 0.0164 - val_accuracy: 0.9945 - val_precision_1: 0.9928 - val_recall_1: 0.9870\n",
      "Epoch 68/1000\n",
      "1035/1035 [==============================] - 0s 474us/step - loss: 0.0231 - binary_crossentropy: 0.0210 - accuracy: 0.9928 - precision_1: 0.9819 - recall_1: 0.9921 - val_loss: 0.0216 - val_binary_crossentropy: 0.0216 - val_accuracy: 0.9929 - val_precision_1: 0.9787 - val_recall_1: 0.9955\n",
      "Epoch 69/1000\n",
      "1035/1035 [==============================] - 1s 487us/step - loss: 0.0232 - binary_crossentropy: 0.0215 - accuracy: 0.9926 - precision_1: 0.9817 - recall_1: 0.9916 - val_loss: 0.0199 - val_binary_crossentropy: 0.0199 - val_accuracy: 0.9935 - val_precision_1: 0.9811 - val_recall_1: 0.9952\n",
      "Epoch 70/1000\n",
      "1035/1035 [==============================] - 0s 474us/step - loss: 0.0232 - binary_crossentropy: 0.0216 - accuracy: 0.9928 - precision_1: 0.9819 - recall_1: 0.9923 - val_loss: 0.0182 - val_binary_crossentropy: 0.0182 - val_accuracy: 0.9946 - val_precision_1: 0.9863 - val_recall_1: 0.9940\n",
      "Epoch 71/1000\n",
      "1035/1035 [==============================] - 1s 516us/step - loss: 0.0231 - binary_crossentropy: 0.0214 - accuracy: 0.9929 - precision_1: 0.9820 - recall_1: 0.9923 - val_loss: 0.0184 - val_binary_crossentropy: 0.0184 - val_accuracy: 0.9937 - val_precision_1: 0.9919 - val_recall_1: 0.9847\n",
      "Epoch 72/1000\n",
      "1035/1035 [==============================] - 0s 450us/step - loss: 0.0230 - binary_crossentropy: 0.0211 - accuracy: 0.9926 - precision_1: 0.9813 - recall_1: 0.9919 - val_loss: 0.0169 - val_binary_crossentropy: 0.0169 - val_accuracy: 0.9945 - val_precision_1: 0.9872 - val_recall_1: 0.9925\n",
      "Epoch 73/1000\n",
      "1035/1035 [==============================] - 0s 451us/step - loss: 0.0227 - binary_crossentropy: 0.0208 - accuracy: 0.9930 - precision_1: 0.9828 - recall_1: 0.9921 - val_loss: 0.0216 - val_binary_crossentropy: 0.0216 - val_accuracy: 0.9922 - val_precision_1: 0.9782 - val_recall_1: 0.9935\n",
      "Epoch 74/1000\n",
      "1035/1035 [==============================] - 0s 434us/step - loss: 0.0226 - binary_crossentropy: 0.0208 - accuracy: 0.9930 - precision_1: 0.9824 - recall_1: 0.9923 - val_loss: 0.0168 - val_binary_crossentropy: 0.0168 - val_accuracy: 0.9947 - val_precision_1: 0.9915 - val_recall_1: 0.9888\n",
      "Epoch 75/1000\n",
      "1035/1035 [==============================] - 0s 468us/step - loss: 0.0226 - binary_crossentropy: 0.0208 - accuracy: 0.9929 - precision_1: 0.9825 - recall_1: 0.9918 - val_loss: 0.0171 - val_binary_crossentropy: 0.0171 - val_accuracy: 0.9946 - val_precision_1: 0.9884 - val_recall_1: 0.9918\n",
      "Epoch 76/1000\n",
      "1035/1035 [==============================] - 0s 475us/step - loss: 0.0225 - binary_crossentropy: 0.0206 - accuracy: 0.9930 - precision_1: 0.9827 - recall_1: 0.9921 - val_loss: 0.0172 - val_binary_crossentropy: 0.0172 - val_accuracy: 0.9944 - val_precision_1: 0.9892 - val_recall_1: 0.9903\n",
      "Epoch 77/1000\n",
      "1035/1035 [==============================] - 0s 454us/step - loss: 0.0226 - binary_crossentropy: 0.0209 - accuracy: 0.9931 - precision_1: 0.9827 - recall_1: 0.9923 - val_loss: 0.0172 - val_binary_crossentropy: 0.0172 - val_accuracy: 0.9944 - val_precision_1: 0.9866 - val_recall_1: 0.9930\n",
      "Epoch 78/1000\n",
      "1035/1035 [==============================] - 0s 463us/step - loss: 0.0227 - binary_crossentropy: 0.0208 - accuracy: 0.9929 - precision_1: 0.9825 - recall_1: 0.9918 - val_loss: 0.0220 - val_binary_crossentropy: 0.0220 - val_accuracy: 0.9927 - val_precision_1: 0.9793 - val_recall_1: 0.9942\n",
      "Epoch 79/1000\n",
      "1035/1035 [==============================] - 1s 499us/step - loss: 0.0222 - binary_crossentropy: 0.0202 - accuracy: 0.9931 - precision_1: 0.9828 - recall_1: 0.9922 - val_loss: 0.0243 - val_binary_crossentropy: 0.0243 - val_accuracy: 0.9917 - val_precision_1: 0.9741 - val_recall_1: 0.9960\n",
      "Epoch 80/1000\n",
      "1035/1035 [==============================] - 0s 434us/step - loss: 0.0222 - binary_crossentropy: 0.0206 - accuracy: 0.9929 - precision_1: 0.9823 - recall_1: 0.9919 - val_loss: 0.0220 - val_binary_crossentropy: 0.0220 - val_accuracy: 0.9924 - val_precision_1: 0.9782 - val_recall_1: 0.9943\n",
      "Epoch 81/1000\n",
      "1035/1035 [==============================] - 1s 582us/step - loss: 0.0223 - binary_crossentropy: 0.0204 - accuracy: 0.9931 - precision_1: 0.9831 - recall_1: 0.9919 - val_loss: 0.0165 - val_binary_crossentropy: 0.0165 - val_accuracy: 0.9947 - val_precision_1: 0.9912 - val_recall_1: 0.9895\n",
      "Epoch 82/1000\n",
      "1035/1035 [==============================] - 1s 521us/step - loss: 0.0219 - binary_crossentropy: 0.0200 - accuracy: 0.9933 - precision_1: 0.9838 - recall_1: 0.9921 - val_loss: 0.0204 - val_binary_crossentropy: 0.0204 - val_accuracy: 0.9937 - val_precision_1: 0.9806 - val_recall_1: 0.9963\n",
      "Epoch 83/1000\n",
      "1035/1035 [==============================] - 1s 593us/step - loss: 0.0220 - binary_crossentropy: 0.0202 - accuracy: 0.9932 - precision_1: 0.9834 - recall_1: 0.9919 - val_loss: 0.0207 - val_binary_crossentropy: 0.0207 - val_accuracy: 0.9935 - val_precision_1: 0.9805 - val_recall_1: 0.9960\n",
      "Epoch 84/1000\n",
      "1035/1035 [==============================] - 1s 539us/step - loss: 0.0219 - binary_crossentropy: 0.0200 - accuracy: 0.9933 - precision_1: 0.9834 - recall_1: 0.9924 - val_loss: 0.0178 - val_binary_crossentropy: 0.0178 - val_accuracy: 0.9948 - val_precision_1: 0.9853 - val_recall_1: 0.9958\n",
      "Epoch 85/1000\n",
      "1035/1035 [==============================] - 0s 475us/step - loss: 0.0219 - binary_crossentropy: 0.0201 - accuracy: 0.9931 - precision_1: 0.9831 - recall_1: 0.9921 - val_loss: 0.0156 - val_binary_crossentropy: 0.0156 - val_accuracy: 0.9952 - val_precision_1: 0.9936 - val_recall_1: 0.9888\n",
      "Epoch 86/1000\n",
      "1035/1035 [==============================] - 1s 517us/step - loss: 0.0219 - binary_crossentropy: 0.0200 - accuracy: 0.9931 - precision_1: 0.9828 - recall_1: 0.9923 - val_loss: 0.0180 - val_binary_crossentropy: 0.0180 - val_accuracy: 0.9946 - val_precision_1: 0.9880 - val_recall_1: 0.9922\n",
      "Epoch 87/1000\n",
      "1035/1035 [==============================] - 1s 546us/step - loss: 0.0214 - binary_crossentropy: 0.0195 - accuracy: 0.9939 - precision_1: 0.9851 - recall_1: 0.9929 - val_loss: 0.0202 - val_binary_crossentropy: 0.0202 - val_accuracy: 0.9934 - val_precision_1: 0.9802 - val_recall_1: 0.9960\n",
      "Epoch 88/1000\n",
      "1035/1035 [==============================] - 1s 537us/step - loss: 0.0217 - binary_crossentropy: 0.0199 - accuracy: 0.9934 - precision_1: 0.9836 - recall_1: 0.9924 - val_loss: 0.0165 - val_binary_crossentropy: 0.0165 - val_accuracy: 0.9950 - val_precision_1: 0.9879 - val_recall_1: 0.9937\n",
      "Epoch 89/1000\n",
      "1035/1035 [==============================] - 0s 453us/step - loss: 0.0216 - binary_crossentropy: 0.0198 - accuracy: 0.9931 - precision_1: 0.9829 - recall_1: 0.9923 - val_loss: 0.0171 - val_binary_crossentropy: 0.0171 - val_accuracy: 0.9949 - val_precision_1: 0.9869 - val_recall_1: 0.9945\n",
      "Epoch 90/1000\n",
      "1035/1035 [==============================] - 1s 520us/step - loss: 0.0215 - binary_crossentropy: 0.0195 - accuracy: 0.9937 - precision_1: 0.9846 - recall_1: 0.9927 - val_loss: 0.0154 - val_binary_crossentropy: 0.0154 - val_accuracy: 0.9952 - val_precision_1: 0.9912 - val_recall_1: 0.9912\n",
      "Epoch 91/1000\n",
      "1035/1035 [==============================] - 1s 492us/step - loss: 0.0216 - binary_crossentropy: 0.0197 - accuracy: 0.9934 - precision_1: 0.9836 - recall_1: 0.9926 - val_loss: 0.0175 - val_binary_crossentropy: 0.0175 - val_accuracy: 0.9946 - val_precision_1: 0.9850 - val_recall_1: 0.9952\n",
      "Epoch 92/1000\n",
      "1035/1035 [==============================] - 0s 463us/step - loss: 0.0217 - binary_crossentropy: 0.0199 - accuracy: 0.9935 - precision_1: 0.9837 - recall_1: 0.9928 - val_loss: 0.0156 - val_binary_crossentropy: 0.0156 - val_accuracy: 0.9952 - val_precision_1: 0.9915 - val_recall_1: 0.9908\n",
      "Epoch 93/1000\n",
      "1035/1035 [==============================] - 0s 470us/step - loss: 0.0217 - binary_crossentropy: 0.0199 - accuracy: 0.9932 - precision_1: 0.9836 - recall_1: 0.9918 - val_loss: 0.0170 - val_binary_crossentropy: 0.0170 - val_accuracy: 0.9938 - val_precision_1: 0.9915 - val_recall_1: 0.9857\n",
      "Epoch 94/1000\n",
      "1035/1035 [==============================] - 1s 584us/step - loss: 0.0216 - binary_crossentropy: 0.0198 - accuracy: 0.9934 - precision_1: 0.9839 - recall_1: 0.9922 - val_loss: 0.0190 - val_binary_crossentropy: 0.0190 - val_accuracy: 0.9942 - val_precision_1: 0.9826 - val_recall_1: 0.9962\n",
      "Epoch 95/1000\n",
      "1035/1035 [==============================] - 1s 620us/step - loss: 0.0215 - binary_crossentropy: 0.0196 - accuracy: 0.9933 - precision_1: 0.9836 - recall_1: 0.9924 - val_loss: 0.0176 - val_binary_crossentropy: 0.0176 - val_accuracy: 0.9943 - val_precision_1: 0.9866 - val_recall_1: 0.9927\n",
      "Epoch 96/1000\n",
      "1035/1035 [==============================] - 0s 452us/step - loss: 0.0211 - binary_crossentropy: 0.0192 - accuracy: 0.9937 - precision_1: 0.9846 - recall_1: 0.9925 - val_loss: 0.0210 - val_binary_crossentropy: 0.0210 - val_accuracy: 0.9936 - val_precision_1: 0.9827 - val_recall_1: 0.9938\n",
      "Epoch 97/1000\n",
      "1035/1035 [==============================] - 0s 480us/step - loss: 0.0212 - binary_crossentropy: 0.0194 - accuracy: 0.9935 - precision_1: 0.9836 - recall_1: 0.9928 - val_loss: 0.0153 - val_binary_crossentropy: 0.0153 - val_accuracy: 0.9953 - val_precision_1: 0.9920 - val_recall_1: 0.9908\n",
      "Epoch 98/1000\n",
      "1035/1035 [==============================] - 0s 448us/step - loss: 0.0212 - binary_crossentropy: 0.0193 - accuracy: 0.9933 - precision_1: 0.9837 - recall_1: 0.9922 - val_loss: 0.0162 - val_binary_crossentropy: 0.0162 - val_accuracy: 0.9947 - val_precision_1: 0.9913 - val_recall_1: 0.9893\n",
      "Epoch 99/1000\n",
      "1035/1035 [==============================] - 0s 450us/step - loss: 0.0210 - binary_crossentropy: 0.0191 - accuracy: 0.9935 - precision_1: 0.9844 - recall_1: 0.9923 - val_loss: 0.0163 - val_binary_crossentropy: 0.0163 - val_accuracy: 0.9949 - val_precision_1: 0.9877 - val_recall_1: 0.9937\n",
      "Epoch 100/1000\n",
      "1035/1035 [==============================] - 0s 462us/step - loss: 0.0209 - binary_crossentropy: 0.0189 - accuracy: 0.9938 - precision_1: 0.9849 - recall_1: 0.9927 - val_loss: 0.0218 - val_binary_crossentropy: 0.0218 - val_accuracy: 0.9925 - val_precision_1: 0.9766 - val_recall_1: 0.9962\n",
      "Epoch 101/1000\n",
      "1035/1035 [==============================] - 0s 482us/step - loss: 0.0211 - binary_crossentropy: 0.0194 - accuracy: 0.9934 - precision_1: 0.9840 - recall_1: 0.9922 - val_loss: 0.0145 - val_binary_crossentropy: 0.0145 - val_accuracy: 0.9954 - val_precision_1: 0.9920 - val_recall_1: 0.9912\n",
      "Epoch 102/1000\n",
      "1035/1035 [==============================] - 0s 448us/step - loss: 0.0209 - binary_crossentropy: 0.0189 - accuracy: 0.9937 - precision_1: 0.9847 - recall_1: 0.9924 - val_loss: 0.0206 - val_binary_crossentropy: 0.0206 - val_accuracy: 0.9933 - val_precision_1: 0.9794 - val_recall_1: 0.9963\n",
      "Epoch 103/1000\n",
      "1035/1035 [==============================] - 0s 450us/step - loss: 0.0207 - binary_crossentropy: 0.0187 - accuracy: 0.9939 - precision_1: 0.9856 - recall_1: 0.9922 - val_loss: 0.0251 - val_binary_crossentropy: 0.0251 - val_accuracy: 0.9914 - val_precision_1: 0.9733 - val_recall_1: 0.9958\n",
      "Epoch 104/1000\n",
      "1035/1035 [==============================] - 0s 450us/step - loss: 0.0206 - binary_crossentropy: 0.0187 - accuracy: 0.9938 - precision_1: 0.9852 - recall_1: 0.9925 - val_loss: 0.0172 - val_binary_crossentropy: 0.0172 - val_accuracy: 0.9945 - val_precision_1: 0.9871 - val_recall_1: 0.9928\n",
      "Epoch 105/1000\n",
      "1035/1035 [==============================] - 0s 478us/step - loss: 0.0204 - binary_crossentropy: 0.0185 - accuracy: 0.9939 - precision_1: 0.9851 - recall_1: 0.9930 - val_loss: 0.0156 - val_binary_crossentropy: 0.0156 - val_accuracy: 0.9952 - val_precision_1: 0.9876 - val_recall_1: 0.9947\n",
      "Epoch 106/1000\n",
      "1035/1035 [==============================] - 0s 462us/step - loss: 0.0203 - binary_crossentropy: 0.0183 - accuracy: 0.9939 - precision_1: 0.9852 - recall_1: 0.9928 - val_loss: 0.0170 - val_binary_crossentropy: 0.0170 - val_accuracy: 0.9946 - val_precision_1: 0.9860 - val_recall_1: 0.9942\n",
      "Epoch 107/1000\n",
      "1035/1035 [==============================] - 0s 448us/step - loss: 0.0205 - binary_crossentropy: 0.0185 - accuracy: 0.9938 - precision_1: 0.9850 - recall_1: 0.9927 - val_loss: 0.0159 - val_binary_crossentropy: 0.0159 - val_accuracy: 0.9952 - val_precision_1: 0.9904 - val_recall_1: 0.9922\n",
      "Epoch 108/1000\n",
      "1035/1035 [==============================] - 0s 450us/step - loss: 0.0202 - binary_crossentropy: 0.0184 - accuracy: 0.9938 - precision_1: 0.9851 - recall_1: 0.9925 - val_loss: 0.0142 - val_binary_crossentropy: 0.0142 - val_accuracy: 0.9959 - val_precision_1: 0.9930 - val_recall_1: 0.9918\n",
      "Epoch 109/1000\n",
      "1035/1035 [==============================] - 0s 479us/step - loss: 0.0201 - binary_crossentropy: 0.0180 - accuracy: 0.9940 - precision_1: 0.9859 - recall_1: 0.9925 - val_loss: 0.0146 - val_binary_crossentropy: 0.0146 - val_accuracy: 0.9956 - val_precision_1: 0.9918 - val_recall_1: 0.9922\n",
      "Epoch 110/1000\n",
      "1035/1035 [==============================] - 0s 450us/step - loss: 0.0200 - binary_crossentropy: 0.0180 - accuracy: 0.9939 - precision_1: 0.9852 - recall_1: 0.9929 - val_loss: 0.0144 - val_binary_crossentropy: 0.0144 - val_accuracy: 0.9958 - val_precision_1: 0.9927 - val_recall_1: 0.9920\n",
      "Epoch 111/1000\n",
      "1035/1035 [==============================] - 1s 483us/step - loss: 0.0199 - binary_crossentropy: 0.0179 - accuracy: 0.9941 - precision_1: 0.9865 - recall_1: 0.9922 - val_loss: 0.0136 - val_binary_crossentropy: 0.0136 - val_accuracy: 0.9962 - val_precision_1: 0.9922 - val_recall_1: 0.9940\n",
      "Epoch 112/1000\n",
      "1035/1035 [==============================] - 0s 463us/step - loss: 0.0196 - binary_crossentropy: 0.0176 - accuracy: 0.9943 - precision_1: 0.9868 - recall_1: 0.9926 - val_loss: 0.0182 - val_binary_crossentropy: 0.0182 - val_accuracy: 0.9936 - val_precision_1: 0.9824 - val_recall_1: 0.9942\n",
      "Epoch 113/1000\n",
      "1035/1035 [==============================] - 0s 479us/step - loss: 0.0195 - binary_crossentropy: 0.0176 - accuracy: 0.9943 - precision_1: 0.9866 - recall_1: 0.9930 - val_loss: 0.0137 - val_binary_crossentropy: 0.0137 - val_accuracy: 0.9958 - val_precision_1: 0.9927 - val_recall_1: 0.9920\n",
      "Epoch 114/1000\n",
      "1035/1035 [==============================] - 0s 450us/step - loss: 0.0198 - binary_crossentropy: 0.0178 - accuracy: 0.9940 - precision_1: 0.9858 - recall_1: 0.9925 - val_loss: 0.0148 - val_binary_crossentropy: 0.0148 - val_accuracy: 0.9958 - val_precision_1: 0.9917 - val_recall_1: 0.9930\n",
      "Epoch 115/1000\n",
      "1035/1035 [==============================] - 0s 448us/step - loss: 0.0189 - binary_crossentropy: 0.0168 - accuracy: 0.9942 - precision_1: 0.9863 - recall_1: 0.9929 - val_loss: 0.0134 - val_binary_crossentropy: 0.0134 - val_accuracy: 0.9962 - val_precision_1: 0.9942 - val_recall_1: 0.9920\n",
      "Epoch 116/1000\n",
      "1035/1035 [==============================] - 0s 449us/step - loss: 0.0188 - binary_crossentropy: 0.0166 - accuracy: 0.9945 - precision_1: 0.9871 - recall_1: 0.9929 - val_loss: 0.0135 - val_binary_crossentropy: 0.0135 - val_accuracy: 0.9961 - val_precision_1: 0.9933 - val_recall_1: 0.9922\n",
      "Epoch 117/1000\n",
      "1035/1035 [==============================] - 0s 477us/step - loss: 0.0189 - binary_crossentropy: 0.0169 - accuracy: 0.9944 - precision_1: 0.9869 - recall_1: 0.9930 - val_loss: 0.0125 - val_binary_crossentropy: 0.0125 - val_accuracy: 0.9968 - val_precision_1: 0.9940 - val_recall_1: 0.9943\n",
      "Epoch 118/1000\n",
      "1035/1035 [==============================] - 0s 460us/step - loss: 0.0187 - binary_crossentropy: 0.0165 - accuracy: 0.9945 - precision_1: 0.9866 - recall_1: 0.9934 - val_loss: 0.0150 - val_binary_crossentropy: 0.0150 - val_accuracy: 0.9952 - val_precision_1: 0.9865 - val_recall_1: 0.9962\n",
      "Epoch 119/1000\n",
      "1035/1035 [==============================] - 0s 446us/step - loss: 0.0184 - binary_crossentropy: 0.0162 - accuracy: 0.9945 - precision_1: 0.9867 - recall_1: 0.9934 - val_loss: 0.0123 - val_binary_crossentropy: 0.0123 - val_accuracy: 0.9966 - val_precision_1: 0.9940 - val_recall_1: 0.9935\n",
      "Epoch 120/1000\n",
      "1035/1035 [==============================] - 0s 448us/step - loss: 0.0185 - binary_crossentropy: 0.0165 - accuracy: 0.9944 - precision_1: 0.9864 - recall_1: 0.9934 - val_loss: 0.0125 - val_binary_crossentropy: 0.0125 - val_accuracy: 0.9966 - val_precision_1: 0.9932 - val_recall_1: 0.9945\n",
      "Epoch 121/1000\n",
      "1035/1035 [==============================] - 0s 475us/step - loss: 0.0183 - binary_crossentropy: 0.0161 - accuracy: 0.9945 - precision_1: 0.9872 - recall_1: 0.9930 - val_loss: 0.0171 - val_binary_crossentropy: 0.0171 - val_accuracy: 0.9945 - val_precision_1: 0.9835 - val_recall_1: 0.9965\n",
      "Epoch 122/1000\n",
      "1035/1035 [==============================] - 0s 449us/step - loss: 0.0182 - binary_crossentropy: 0.0161 - accuracy: 0.9945 - precision_1: 0.9870 - recall_1: 0.9931 - val_loss: 0.0132 - val_binary_crossentropy: 0.0132 - val_accuracy: 0.9959 - val_precision_1: 0.9907 - val_recall_1: 0.9943\n",
      "Epoch 123/1000\n",
      "1035/1035 [==============================] - 0s 459us/step - loss: 0.0180 - binary_crossentropy: 0.0159 - accuracy: 0.9948 - precision_1: 0.9873 - recall_1: 0.9939 - val_loss: 0.0161 - val_binary_crossentropy: 0.0161 - val_accuracy: 0.9950 - val_precision_1: 0.9852 - val_recall_1: 0.9965\n",
      "Epoch 124/1000\n",
      "1035/1035 [==============================] - 0s 448us/step - loss: 0.0179 - binary_crossentropy: 0.0157 - accuracy: 0.9948 - precision_1: 0.9877 - recall_1: 0.9934 - val_loss: 0.0142 - val_binary_crossentropy: 0.0142 - val_accuracy: 0.9956 - val_precision_1: 0.9883 - val_recall_1: 0.9958\n",
      "Epoch 125/1000\n",
      "1035/1035 [==============================] - 0s 479us/step - loss: 0.0180 - binary_crossentropy: 0.0158 - accuracy: 0.9949 - precision_1: 0.9878 - recall_1: 0.9936 - val_loss: 0.0136 - val_binary_crossentropy: 0.0136 - val_accuracy: 0.9958 - val_precision_1: 0.9915 - val_recall_1: 0.9932\n",
      "Epoch 126/1000\n",
      "1035/1035 [==============================] - 0s 455us/step - loss: 0.0178 - binary_crossentropy: 0.0156 - accuracy: 0.9949 - precision_1: 0.9877 - recall_1: 0.9939 - val_loss: 0.0125 - val_binary_crossentropy: 0.0125 - val_accuracy: 0.9965 - val_precision_1: 0.9925 - val_recall_1: 0.9947\n",
      "Epoch 127/1000\n",
      "1035/1035 [==============================] - 1s 485us/step - loss: 0.0177 - binary_crossentropy: 0.0156 - accuracy: 0.9948 - precision_1: 0.9877 - recall_1: 0.9936 - val_loss: 0.0129 - val_binary_crossentropy: 0.0129 - val_accuracy: 0.9960 - val_precision_1: 0.9918 - val_recall_1: 0.9935\n",
      "Epoch 128/1000\n",
      "1035/1035 [==============================] - 0s 453us/step - loss: 0.0171 - binary_crossentropy: 0.0151 - accuracy: 0.9951 - precision_1: 0.9886 - recall_1: 0.9938 - val_loss: 0.0140 - val_binary_crossentropy: 0.0140 - val_accuracy: 0.9959 - val_precision_1: 0.9883 - val_recall_1: 0.9967\n",
      "Epoch 129/1000\n",
      "1035/1035 [==============================] - 0s 481us/step - loss: 0.0177 - binary_crossentropy: 0.0153 - accuracy: 0.9949 - precision_1: 0.9876 - recall_1: 0.9939 - val_loss: 0.0164 - val_binary_crossentropy: 0.0164 - val_accuracy: 0.9950 - val_precision_1: 0.9849 - val_recall_1: 0.9970\n",
      "Epoch 130/1000\n",
      "1035/1035 [==============================] - 1s 512us/step - loss: 0.0173 - binary_crossentropy: 0.0151 - accuracy: 0.9949 - precision_1: 0.9879 - recall_1: 0.9939 - val_loss: 0.0147 - val_binary_crossentropy: 0.0147 - val_accuracy: 0.9956 - val_precision_1: 0.9883 - val_recall_1: 0.9958\n",
      "Epoch 131/1000\n",
      "1035/1035 [==============================] - 1s 510us/step - loss: 0.0173 - binary_crossentropy: 0.0151 - accuracy: 0.9949 - precision_1: 0.9877 - recall_1: 0.9938 - val_loss: 0.0123 - val_binary_crossentropy: 0.0123 - val_accuracy: 0.9964 - val_precision_1: 0.9923 - val_recall_1: 0.9945\n",
      "Epoch 132/1000\n",
      "1035/1035 [==============================] - 1s 513us/step - loss: 0.0170 - binary_crossentropy: 0.0148 - accuracy: 0.9953 - precision_1: 0.9890 - recall_1: 0.9938 - val_loss: 0.0156 - val_binary_crossentropy: 0.0156 - val_accuracy: 0.9947 - val_precision_1: 0.9842 - val_recall_1: 0.9967\n",
      "Epoch 133/1000\n",
      "1035/1035 [==============================] - 0s 451us/step - loss: 0.0168 - binary_crossentropy: 0.0147 - accuracy: 0.9953 - precision_1: 0.9887 - recall_1: 0.9944 - val_loss: 0.0123 - val_binary_crossentropy: 0.0123 - val_accuracy: 0.9967 - val_precision_1: 0.9917 - val_recall_1: 0.9962\n",
      "Epoch 134/1000\n",
      "1035/1035 [==============================] - 1s 486us/step - loss: 0.0167 - binary_crossentropy: 0.0146 - accuracy: 0.9952 - precision_1: 0.9887 - recall_1: 0.9939 - val_loss: 0.0119 - val_binary_crossentropy: 0.0119 - val_accuracy: 0.9963 - val_precision_1: 0.9948 - val_recall_1: 0.9917\n",
      "Epoch 135/1000\n",
      "1035/1035 [==============================] - 1s 501us/step - loss: 0.0164 - binary_crossentropy: 0.0141 - accuracy: 0.9955 - precision_1: 0.9891 - recall_1: 0.9946 - val_loss: 0.0130 - val_binary_crossentropy: 0.0130 - val_accuracy: 0.9961 - val_precision_1: 0.9896 - val_recall_1: 0.9962\n",
      "Epoch 136/1000\n",
      "1035/1035 [==============================] - 0s 451us/step - loss: 0.0167 - binary_crossentropy: 0.0145 - accuracy: 0.9953 - precision_1: 0.9887 - recall_1: 0.9943 - val_loss: 0.0127 - val_binary_crossentropy: 0.0127 - val_accuracy: 0.9964 - val_precision_1: 0.9907 - val_recall_1: 0.9960\n",
      "Epoch 137/1000\n",
      "1035/1035 [==============================] - 0s 461us/step - loss: 0.0163 - binary_crossentropy: 0.0140 - accuracy: 0.9955 - precision_1: 0.9896 - recall_1: 0.9941 - val_loss: 0.0140 - val_binary_crossentropy: 0.0140 - val_accuracy: 0.9957 - val_precision_1: 0.9878 - val_recall_1: 0.9965\n",
      "Epoch 138/1000\n",
      "1035/1035 [==============================] - 0s 449us/step - loss: 0.0166 - binary_crossentropy: 0.0143 - accuracy: 0.9952 - precision_1: 0.9884 - recall_1: 0.9941 - val_loss: 0.0122 - val_binary_crossentropy: 0.0122 - val_accuracy: 0.9962 - val_precision_1: 0.9904 - val_recall_1: 0.9957\n",
      "Epoch 139/1000\n",
      "1035/1035 [==============================] - 0s 477us/step - loss: 0.0164 - binary_crossentropy: 0.0142 - accuracy: 0.9953 - precision_1: 0.9886 - recall_1: 0.9943 - val_loss: 0.0122 - val_binary_crossentropy: 0.0122 - val_accuracy: 0.9966 - val_precision_1: 0.9911 - val_recall_1: 0.9967\n",
      "Epoch 140/1000\n",
      "1035/1035 [==============================] - 0s 447us/step - loss: 0.0165 - binary_crossentropy: 0.0144 - accuracy: 0.9952 - precision_1: 0.9887 - recall_1: 0.9941 - val_loss: 0.0128 - val_binary_crossentropy: 0.0128 - val_accuracy: 0.9964 - val_precision_1: 0.9906 - val_recall_1: 0.9963\n",
      "Epoch 141/1000\n",
      "1035/1035 [==============================] - 0s 448us/step - loss: 0.0163 - binary_crossentropy: 0.0140 - accuracy: 0.9954 - precision_1: 0.9890 - recall_1: 0.9944 - val_loss: 0.0181 - val_binary_crossentropy: 0.0181 - val_accuracy: 0.9938 - val_precision_1: 0.9800 - val_recall_1: 0.9975\n",
      "Epoch 142/1000\n",
      "1035/1035 [==============================] - 1s 490us/step - loss: 0.0161 - binary_crossentropy: 0.0140 - accuracy: 0.9953 - precision_1: 0.9888 - recall_1: 0.9943 - val_loss: 0.0112 - val_binary_crossentropy: 0.0112 - val_accuracy: 0.9966 - val_precision_1: 0.9950 - val_recall_1: 0.9927\n",
      "Epoch 143/1000\n",
      "1035/1035 [==============================] - 0s 448us/step - loss: 0.0159 - binary_crossentropy: 0.0137 - accuracy: 0.9953 - precision_1: 0.9890 - recall_1: 0.9942 - val_loss: 0.0131 - val_binary_crossentropy: 0.0131 - val_accuracy: 0.9959 - val_precision_1: 0.9883 - val_recall_1: 0.9967\n",
      "Epoch 144/1000\n",
      "1035/1035 [==============================] - 0s 448us/step - loss: 0.0160 - binary_crossentropy: 0.0139 - accuracy: 0.9956 - precision_1: 0.9895 - recall_1: 0.9944 - val_loss: 0.0106 - val_binary_crossentropy: 0.0106 - val_accuracy: 0.9968 - val_precision_1: 0.9971 - val_recall_1: 0.9910\n",
      "Epoch 145/1000\n",
      "1035/1035 [==============================] - 0s 445us/step - loss: 0.0163 - binary_crossentropy: 0.0140 - accuracy: 0.9954 - precision_1: 0.9894 - recall_1: 0.9940 - val_loss: 0.0123 - val_binary_crossentropy: 0.0123 - val_accuracy: 0.9963 - val_precision_1: 0.9902 - val_recall_1: 0.9962\n",
      "Epoch 146/1000\n",
      "1035/1035 [==============================] - 1s 494us/step - loss: 0.0161 - binary_crossentropy: 0.0139 - accuracy: 0.9954 - precision_1: 0.9888 - recall_1: 0.9946 - val_loss: 0.0104 - val_binary_crossentropy: 0.0104 - val_accuracy: 0.9975 - val_precision_1: 0.9965 - val_recall_1: 0.9942\n",
      "Epoch 147/1000\n",
      "1035/1035 [==============================] - 0s 445us/step - loss: 0.0163 - binary_crossentropy: 0.0140 - accuracy: 0.9953 - precision_1: 0.9890 - recall_1: 0.9940 - val_loss: 0.0120 - val_binary_crossentropy: 0.0120 - val_accuracy: 0.9968 - val_precision_1: 0.9925 - val_recall_1: 0.9958\n",
      "Epoch 148/1000\n",
      "1035/1035 [==============================] - 0s 440us/step - loss: 0.0157 - binary_crossentropy: 0.0136 - accuracy: 0.9956 - precision_1: 0.9894 - recall_1: 0.9947 - val_loss: 0.0117 - val_binary_crossentropy: 0.0117 - val_accuracy: 0.9967 - val_precision_1: 0.9919 - val_recall_1: 0.9960\n",
      "Epoch 149/1000\n",
      "1035/1035 [==============================] - 0s 445us/step - loss: 0.0160 - binary_crossentropy: 0.0138 - accuracy: 0.9954 - precision_1: 0.9890 - recall_1: 0.9942 - val_loss: 0.0118 - val_binary_crossentropy: 0.0118 - val_accuracy: 0.9970 - val_precision_1: 0.9924 - val_recall_1: 0.9965\n",
      "Epoch 150/1000\n",
      "1035/1035 [==============================] - 0s 476us/step - loss: 0.0161 - binary_crossentropy: 0.0139 - accuracy: 0.9954 - precision_1: 0.9891 - recall_1: 0.9942 - val_loss: 0.0190 - val_binary_crossentropy: 0.0190 - val_accuracy: 0.9931 - val_precision_1: 0.9782 - val_recall_1: 0.9968\n",
      "Epoch 151/1000\n",
      "1035/1035 [==============================] - 0s 463us/step - loss: 0.0157 - binary_crossentropy: 0.0134 - accuracy: 0.9956 - precision_1: 0.9896 - recall_1: 0.9944 - val_loss: 0.0134 - val_binary_crossentropy: 0.0134 - val_accuracy: 0.9960 - val_precision_1: 0.9965 - val_recall_1: 0.9888\n",
      "Epoch 152/1000\n",
      "1035/1035 [==============================] - 0s 446us/step - loss: 0.0156 - binary_crossentropy: 0.0134 - accuracy: 0.9956 - precision_1: 0.9893 - recall_1: 0.9950 - val_loss: 0.0126 - val_binary_crossentropy: 0.0126 - val_accuracy: 0.9961 - val_precision_1: 0.9897 - val_recall_1: 0.9962\n",
      "Epoch 153/1000\n",
      "1035/1035 [==============================] - 0s 474us/step - loss: 0.0157 - binary_crossentropy: 0.0135 - accuracy: 0.9957 - precision_1: 0.9897 - recall_1: 0.9948 - val_loss: 0.0134 - val_binary_crossentropy: 0.0134 - val_accuracy: 0.9960 - val_precision_1: 0.9886 - val_recall_1: 0.9968\n",
      "Epoch 154/1000\n",
      "1035/1035 [==============================] - 0s 446us/step - loss: 0.0156 - binary_crossentropy: 0.0134 - accuracy: 0.9956 - precision_1: 0.9898 - recall_1: 0.9944 - val_loss: 0.0112 - val_binary_crossentropy: 0.0112 - val_accuracy: 0.9970 - val_precision_1: 0.9930 - val_recall_1: 0.9958\n",
      "Epoch 155/1000\n",
      "1035/1035 [==============================] - 0s 446us/step - loss: 0.0153 - binary_crossentropy: 0.0131 - accuracy: 0.9956 - precision_1: 0.9899 - recall_1: 0.9941 - val_loss: 0.0116 - val_binary_crossentropy: 0.0116 - val_accuracy: 0.9967 - val_precision_1: 0.9912 - val_recall_1: 0.9967\n",
      "Epoch 156/1000\n",
      "1035/1035 [==============================] - 0s 449us/step - loss: 0.0155 - binary_crossentropy: 0.0133 - accuracy: 0.9956 - precision_1: 0.9893 - recall_1: 0.9947 - val_loss: 0.0102 - val_binary_crossentropy: 0.0102 - val_accuracy: 0.9977 - val_precision_1: 0.9960 - val_recall_1: 0.9957\n",
      "Epoch 157/1000\n",
      "1035/1035 [==============================] - 0s 474us/step - loss: 0.0156 - binary_crossentropy: 0.0133 - accuracy: 0.9957 - precision_1: 0.9900 - recall_1: 0.9944 - val_loss: 0.0158 - val_binary_crossentropy: 0.0158 - val_accuracy: 0.9945 - val_precision_1: 0.9824 - val_recall_1: 0.9975\n",
      "Epoch 158/1000\n",
      "1035/1035 [==============================] - 0s 450us/step - loss: 0.0156 - binary_crossentropy: 0.0133 - accuracy: 0.9958 - precision_1: 0.9901 - recall_1: 0.9946 - val_loss: 0.0137 - val_binary_crossentropy: 0.0137 - val_accuracy: 0.9951 - val_precision_1: 0.9868 - val_recall_1: 0.9953\n",
      "Epoch 159/1000\n",
      "1035/1035 [==============================] - 0s 447us/step - loss: 0.0150 - binary_crossentropy: 0.0128 - accuracy: 0.9960 - precision_1: 0.9908 - recall_1: 0.9947 - val_loss: 0.0136 - val_binary_crossentropy: 0.0136 - val_accuracy: 0.9959 - val_precision_1: 0.9888 - val_recall_1: 0.9962\n",
      "Epoch 160/1000\n",
      "1035/1035 [==============================] - 1s 490us/step - loss: 0.0160 - binary_crossentropy: 0.0139 - accuracy: 0.9956 - precision_1: 0.9892 - recall_1: 0.9949 - val_loss: 0.0106 - val_binary_crossentropy: 0.0106 - val_accuracy: 0.9973 - val_precision_1: 0.9947 - val_recall_1: 0.9955\n",
      "Epoch 161/1000\n",
      "1035/1035 [==============================] - 0s 465us/step - loss: 0.0150 - binary_crossentropy: 0.0128 - accuracy: 0.9959 - precision_1: 0.9903 - recall_1: 0.9948 - val_loss: 0.0122 - val_binary_crossentropy: 0.0122 - val_accuracy: 0.9961 - val_precision_1: 0.9918 - val_recall_1: 0.9938\n",
      "Epoch 162/1000\n",
      "1035/1035 [==============================] - 0s 451us/step - loss: 0.0153 - binary_crossentropy: 0.0131 - accuracy: 0.9959 - precision_1: 0.9903 - recall_1: 0.9947 - val_loss: 0.0105 - val_binary_crossentropy: 0.0105 - val_accuracy: 0.9972 - val_precision_1: 0.9962 - val_recall_1: 0.9935\n",
      "Epoch 163/1000\n",
      "1035/1035 [==============================] - 0s 450us/step - loss: 0.0151 - binary_crossentropy: 0.0128 - accuracy: 0.9961 - precision_1: 0.9909 - recall_1: 0.9950 - val_loss: 0.0105 - val_binary_crossentropy: 0.0105 - val_accuracy: 0.9968 - val_precision_1: 0.9935 - val_recall_1: 0.9948\n",
      "Epoch 164/1000\n",
      "1035/1035 [==============================] - 1s 494us/step - loss: 0.0150 - binary_crossentropy: 0.0127 - accuracy: 0.9957 - precision_1: 0.9899 - recall_1: 0.9945 - val_loss: 0.0109 - val_binary_crossentropy: 0.0109 - val_accuracy: 0.9966 - val_precision_1: 0.9927 - val_recall_1: 0.9948\n",
      "Epoch 165/1000\n",
      "1035/1035 [==============================] - 0s 448us/step - loss: 0.0152 - binary_crossentropy: 0.0130 - accuracy: 0.9958 - precision_1: 0.9900 - recall_1: 0.9947 - val_loss: 0.0134 - val_binary_crossentropy: 0.0134 - val_accuracy: 0.9958 - val_precision_1: 0.9883 - val_recall_1: 0.9963\n",
      "Epoch 166/1000\n",
      "1035/1035 [==============================] - 0s 449us/step - loss: 0.0149 - binary_crossentropy: 0.0126 - accuracy: 0.9962 - precision_1: 0.9913 - recall_1: 0.9950 - val_loss: 0.0117 - val_binary_crossentropy: 0.0117 - val_accuracy: 0.9964 - val_precision_1: 0.9904 - val_recall_1: 0.9963\n",
      "Epoch 167/1000\n",
      "1035/1035 [==============================] - 0s 477us/step - loss: 0.0152 - binary_crossentropy: 0.0129 - accuracy: 0.9958 - precision_1: 0.9902 - recall_1: 0.9946 - val_loss: 0.0108 - val_binary_crossentropy: 0.0108 - val_accuracy: 0.9972 - val_precision_1: 0.9945 - val_recall_1: 0.9952\n",
      "Epoch 168/1000\n",
      "1035/1035 [==============================] - 0s 461us/step - loss: 0.0152 - binary_crossentropy: 0.0129 - accuracy: 0.9958 - precision_1: 0.9904 - recall_1: 0.9945 - val_loss: 0.0113 - val_binary_crossentropy: 0.0113 - val_accuracy: 0.9969 - val_precision_1: 0.9927 - val_recall_1: 0.9958\n",
      "Epoch 169/1000\n",
      "1035/1035 [==============================] - 0s 448us/step - loss: 0.0152 - binary_crossentropy: 0.0130 - accuracy: 0.9958 - precision_1: 0.9899 - recall_1: 0.9950 - val_loss: 0.0138 - val_binary_crossentropy: 0.0138 - val_accuracy: 0.9957 - val_precision_1: 0.9878 - val_recall_1: 0.9967\n",
      "Epoch 170/1000\n",
      "1035/1035 [==============================] - 1s 496us/step - loss: 0.0151 - binary_crossentropy: 0.0130 - accuracy: 0.9957 - precision_1: 0.9900 - recall_1: 0.9946 - val_loss: 0.0110 - val_binary_crossentropy: 0.0110 - val_accuracy: 0.9969 - val_precision_1: 0.9927 - val_recall_1: 0.9958\n",
      "Epoch 171/1000\n",
      "1035/1035 [==============================] - 1s 487us/step - loss: 0.0147 - binary_crossentropy: 0.0124 - accuracy: 0.9960 - precision_1: 0.9910 - recall_1: 0.9947 - val_loss: 0.0116 - val_binary_crossentropy: 0.0116 - val_accuracy: 0.9964 - val_precision_1: 0.9917 - val_recall_1: 0.9950\n",
      "Epoch 172/1000\n",
      "1035/1035 [==============================] - 0s 462us/step - loss: 0.0148 - binary_crossentropy: 0.0125 - accuracy: 0.9959 - precision_1: 0.9904 - recall_1: 0.9949 - val_loss: 0.0108 - val_binary_crossentropy: 0.0108 - val_accuracy: 0.9970 - val_precision_1: 0.9937 - val_recall_1: 0.9952\n",
      "Epoch 173/1000\n",
      "1035/1035 [==============================] - 0s 448us/step - loss: 0.0150 - binary_crossentropy: 0.0127 - accuracy: 0.9959 - precision_1: 0.9903 - recall_1: 0.9950 - val_loss: 0.0117 - val_binary_crossentropy: 0.0117 - val_accuracy: 0.9963 - val_precision_1: 0.9920 - val_recall_1: 0.9943\n",
      "Epoch 174/1000\n",
      "1035/1035 [==============================] - 0s 478us/step - loss: 0.0147 - binary_crossentropy: 0.0124 - accuracy: 0.9958 - precision_1: 0.9900 - recall_1: 0.9950 - val_loss: 0.0119 - val_binary_crossentropy: 0.0119 - val_accuracy: 0.9966 - val_precision_1: 0.9912 - val_recall_1: 0.9963\n",
      "Epoch 175/1000\n",
      "1035/1035 [==============================] - 0s 448us/step - loss: 0.0149 - binary_crossentropy: 0.0127 - accuracy: 0.9960 - precision_1: 0.9903 - recall_1: 0.9951 - val_loss: 0.0111 - val_binary_crossentropy: 0.0111 - val_accuracy: 0.9970 - val_precision_1: 0.9924 - val_recall_1: 0.9967\n",
      "Epoch 176/1000\n",
      "1035/1035 [==============================] - 0s 461us/step - loss: 0.0147 - binary_crossentropy: 0.0124 - accuracy: 0.9962 - precision_1: 0.9910 - recall_1: 0.9952 - val_loss: 0.0120 - val_binary_crossentropy: 0.0120 - val_accuracy: 0.9964 - val_precision_1: 0.9902 - val_recall_1: 0.9967\n",
      "Epoch 177/1000\n",
      "1035/1035 [==============================] - 0s 476us/step - loss: 0.0149 - binary_crossentropy: 0.0126 - accuracy: 0.9961 - precision_1: 0.9909 - recall_1: 0.9950 - val_loss: 0.0132 - val_binary_crossentropy: 0.0132 - val_accuracy: 0.9953 - val_precision_1: 0.9858 - val_recall_1: 0.9970\n",
      "Epoch 178/1000\n",
      "1035/1035 [==============================] - 0s 446us/step - loss: 0.0149 - binary_crossentropy: 0.0126 - accuracy: 0.9958 - precision_1: 0.9896 - recall_1: 0.9951 - val_loss: 0.0105 - val_binary_crossentropy: 0.0105 - val_accuracy: 0.9972 - val_precision_1: 0.9943 - val_recall_1: 0.9955\n",
      "Epoch 179/1000\n",
      "1035/1035 [==============================] - 0s 444us/step - loss: 0.0147 - binary_crossentropy: 0.0124 - accuracy: 0.9961 - precision_1: 0.9909 - recall_1: 0.9951 - val_loss: 0.0192 - val_binary_crossentropy: 0.0192 - val_accuracy: 0.9934 - val_precision_1: 0.9784 - val_recall_1: 0.9977\n",
      "Epoch 180/1000\n",
      "1035/1035 [==============================] - 0s 457us/step - loss: 0.0146 - binary_crossentropy: 0.0125 - accuracy: 0.9961 - precision_1: 0.9907 - recall_1: 0.9951 - val_loss: 0.0121 - val_binary_crossentropy: 0.0121 - val_accuracy: 0.9963 - val_precision_1: 0.9901 - val_recall_1: 0.9965\n",
      "Epoch 181/1000\n",
      "1035/1035 [==============================] - 0s 482us/step - loss: 0.0146 - binary_crossentropy: 0.0123 - accuracy: 0.9960 - precision_1: 0.9906 - recall_1: 0.9949 - val_loss: 0.0110 - val_binary_crossentropy: 0.0110 - val_accuracy: 0.9967 - val_precision_1: 0.9915 - val_recall_1: 0.9965\n",
      "Epoch 182/1000\n",
      "1035/1035 [==============================] - 0s 447us/step - loss: 0.0145 - binary_crossentropy: 0.0122 - accuracy: 0.9959 - precision_1: 0.9903 - recall_1: 0.9950 - val_loss: 0.0106 - val_binary_crossentropy: 0.0106 - val_accuracy: 0.9970 - val_precision_1: 0.9930 - val_recall_1: 0.9958\n",
      "Epoch 183/1000\n",
      "1035/1035 [==============================] - 0s 440us/step - loss: 0.0145 - binary_crossentropy: 0.0123 - accuracy: 0.9962 - precision_1: 0.9909 - recall_1: 0.9953 - val_loss: 0.0109 - val_binary_crossentropy: 0.0109 - val_accuracy: 0.9969 - val_precision_1: 0.9938 - val_recall_1: 0.9948\n",
      "Epoch 184/1000\n",
      "1035/1035 [==============================] - 1s 488us/step - loss: 0.0146 - binary_crossentropy: 0.0125 - accuracy: 0.9959 - precision_1: 0.9902 - recall_1: 0.9951 - val_loss: 0.0118 - val_binary_crossentropy: 0.0118 - val_accuracy: 0.9966 - val_precision_1: 0.9906 - val_recall_1: 0.9970\n",
      "Epoch 185/1000\n",
      "1035/1035 [==============================] - 0s 447us/step - loss: 0.0143 - binary_crossentropy: 0.0122 - accuracy: 0.9962 - precision_1: 0.9909 - recall_1: 0.9953 - val_loss: 0.0105 - val_binary_crossentropy: 0.0105 - val_accuracy: 0.9972 - val_precision_1: 0.9960 - val_recall_1: 0.9938\n",
      "Epoch 186/1000\n",
      "1035/1035 [==============================] - 0s 448us/step - loss: 0.0146 - binary_crossentropy: 0.0122 - accuracy: 0.9959 - precision_1: 0.9904 - recall_1: 0.9947 - val_loss: 0.0120 - val_binary_crossentropy: 0.0120 - val_accuracy: 0.9962 - val_precision_1: 0.9891 - val_recall_1: 0.9972\n"
     ]
    }
   ],
   "source": [
    "predictors = ['TEMP', 'RH', 'SO42-', 'NO3-', 'CL-']\n",
    "X = df_nh4_zero.loc[:,predictors]\n",
    "y = df_nh4_zero.loc[:,['phase']]\n",
    "\n",
    "scalers = {}\n",
    "for col in ['TEMP', 'RH']:\n",
    "    mean = X[col].mean()\n",
    "    std = X[col].std(ddof=0)\n",
    "    X[col] = (X[col] - mean) / std\n",
    "    scalers[col] = (mean, std)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle=True)\n",
    "\n",
    "#split for val\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25)\n",
    "\n",
    "y_train = y_train.astype(int)\n",
    "y_val = y_val.astype(int)\n",
    "y_test = y_test.astype(int)\n",
    "\n",
    "phase_classifier = Sequential()\n",
    "phase_classifier.add(Dense(input_dim = 5, units=8, activation='tanh'))\n",
    "phase_classifier.add(Dense(units=3,activation='tanh'))\n",
    "phase_classifier.add(Dense(units=3,activation='tanh'))\n",
    "phase_classifier.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "lr_exp_scheduler = ExponentialDecay(\n",
    "    initial_learning_rate = 0.005,\n",
    "    decay_steps=5156,\n",
    "    decay_rate=0.96,\n",
    "    staircase=False\n",
    ")\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.legacy.Adam(learning_rate=lr_exp_scheduler)\n",
    "phase_classifier.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics=['binary_crossentropy', 'accuracy', Precision(), Recall()])\n",
    "\n",
    "#Adding early stopping to prevent overfitting\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=40,\n",
    "    min_delta=0.0005,\n",
    "    mode='max',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train['phase'].values)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "history = phase_classifier.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=64, epochs=1000, shuffle=True, \n",
    "class_weight=class_weight_dict, callbacks=[early_stopping])\n",
    "\n",
    "# phase_classifier.save('/Users/jeremyelvander/Desktop/AQRC Research/ml_files/new_models/phase_classifier_zero.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048ece2d",
   "metadata": {},
   "source": [
    "NH4+ = 0, Liquid/Mix, Water Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcb6c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(scalers, file)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m#DELETE ABOVE\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;66;03m#Establishing parameter input\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "zero_liquid_mix = df_nh4_zero[df_nh4_zero['phase']==0].copy()\n",
    "\n",
    "\n",
    "predictors = ['TEMP', 'RH', 'SO42-', 'NO3-', 'CL-']\n",
    "\n",
    "#Setting up training and test sets\n",
    "X = zero_liquid_mix\n",
    "y = zero_liquid_mix.loc[:,['water_content']]\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=4722)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #Establishing parameter input\n",
    "    filepath = 'NH4_zero/water_content/'\n",
    "\n",
    "    architectures = [\n",
    "        (4, 1),\n",
    "        (8, 4, 1),\n",
    "        (16, 8, 1),\n",
    "        (20, 10, 5, 1),\n",
    "        (32, 16, 8, 1),\n",
    "        (64, 32, 16, 1),\n",
    "        (128, 64, 32, 16, 1)\n",
    "    ]\n",
    "    seeds = (1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n",
    "    results = []\n",
    "\n",
    "    batch_size = 1024\n",
    "    epochs = 500\n",
    "    patience = 40\n",
    "\n",
    "    lr_callback = True\n",
    "\n",
    "    lr = 0.0005\n",
    "\n",
    "    decay_steps = int((len(X_trainval)*0.75)/batch_size * 25)\n",
    "    lr_exp_scheduler = ExponentialDecay(\n",
    "        initial_learning_rate = lr,\n",
    "        decay_steps=decay_steps,\n",
    "        decay_rate=0.96,\n",
    "        staircase=False\n",
    "    )\n",
    "\n",
    "    #Running with processPool\n",
    "    with ProcessPoolExecutor(max_workers=4) as executor:\n",
    "        futures=[\n",
    "            executor.submit(train_model, arch, seed, X_trainval, y_trainval, X_test, y_test, batch_size, epochs, patience, \n",
    "                    lr_exp_scheduler, filepath, lr_callback, water=True)\n",
    "            for arch, seed in itertools.product(architectures, seeds)\n",
    "        ]\n",
    "        results = [f.result() for f in futures]\n",
    "\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "    df_results.to_csv('/Users/jeremyelvander/Desktop/AQRC Research/ml_files/model_training/NH4_zero/water_content/z_lm_water_content_nn.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
